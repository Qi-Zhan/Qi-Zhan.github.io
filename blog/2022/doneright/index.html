<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 《线性代数应该这样学》笔记 | Qi Zhan </title> <meta name="author" content="Qi Zhan"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://qi-zhan.github.io/blog/2022/doneright/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Qi </span> Zhan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">TA </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">《线性代数应该这样学》笔记</h1> <p class="post-meta"> July 29, 2022 • 詹奇 </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fa-solid fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="/blog/category/math"> <i class="fa-solid fa-tag fa-sm"></i> math</a>   </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h2"><a href="#%E9%98%85%E8%AF%BB%E6%9C%AC%E6%96%87%E5%8E%9F%E4%B9%A6%E5%8F%AF%E8%83%BD%E7%9A%84%E6%94%B6%E8%8E%B7">阅读本文(原书)可能的收获</a></li> <li class="toc-entry toc-h2"><a href="#%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86">预备知识</a></li> <li class="toc-entry toc-h2"> <a href="#5-%E7%89%B9%E5%BE%81%E5%80%BC%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E4%B8%8E%E4%B8%8D%E5%8F%98%E5%AD%90%E7%A9%BA%E9%97%B4">5 特征值，特征向量与不变子空间</a> <ul> <li class="toc-entry toc-h3"><a href="#5a-%E4%B8%8D%E5%8F%98%E5%AD%90%E7%A9%BA%E9%97%B4">5.A 不变子空间</a></li> <li class="toc-entry toc-h3"><a href="#5b-%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E4%B8%8E%E4%B8%8A%E4%B8%89%E8%A7%92%E7%9F%A9%E9%98%B5">5.B 特征向量与上三角矩阵</a></li> <li class="toc-entry toc-h3"><a href="#5c-%E7%89%B9%E5%BE%81%E7%A9%BA%E9%97%B4%E4%B8%8E%E5%AF%B9%E8%A7%92%E7%9F%A9%E9%98%B5">5.C 特征空间与对角矩阵</a></li> </ul> </li> <li class="toc-entry toc-h2"><a href="#6-%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4">6 内积空间</a></li> <li class="toc-entry toc-h2"> <a href="#7-%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E7%AE%97%E5%AD%90">7 内积空间中的算子※</a> <ul> <li class="toc-entry toc-h3"><a href="#7a-%E4%BC%B4%E9%9A%8F%E4%B8%8E%E6%AD%A3%E8%A7%84%E7%AE%97%E5%AD%90">7.A 伴随与正规算子</a></li> <li class="toc-entry toc-h3"><a href="#7b-%E8%B0%B1%E5%AE%9A%E7%90%86-the-spectral-theorem-">7.B 谱定理 (The Spectral Theorem) ※</a></li> <li class="toc-entry toc-h3"><a href="#7c-%E6%AD%A3%E7%AE%97%E5%AD%90%E4%B8%8E%E7%AD%89%E8%B7%9D%E5%90%8C%E6%9E%84">7.C 正算子与等距同构</a></li> <li class="toc-entry toc-h3"><a href="#7d-%E6%9E%81%E5%88%86%E8%A7%A3polar-decomposition%E4%B8%8E%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3-singular-value-decomposition-">7.D 极分解(Polar Decomposition)与奇异值分解 (Singular Value Decomposition) ※</a></li> </ul> </li> <li class="toc-entry toc-h2"> <a href="#8-%E5%A4%8D%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E7%AE%97%E5%AD%90">8 复向量空间中的算子</a> <ul> <li class="toc-entry toc-h3"><a href="#8a-%E5%B9%BF%E4%B9%89%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E4%B8%8E%E5%B9%82%E9%9B%B6%E7%AE%97%E5%AD%90">8.A 广义特征向量与幂零算子</a></li> <li class="toc-entry toc-h3"><a href="#8b-%E7%AE%97%E5%AD%90%E7%9A%84%E5%88%86%E8%A7%A3">8.B 算子的分解</a></li> <li class="toc-entry toc-h3"><a href="#8c-%E7%89%B9%E5%BE%81%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%92%8C%E6%9E%81%E5%B0%8F%E5%A4%9A%E9%A1%B9%E5%BC%8F">8.C 特征多项式和极小多项式</a></li> <li class="toc-entry toc-h3"><a href="#8d-%E7%BA%A6%E5%BD%93%E5%9E%8B-jordan-form">8.D 约当型 (Jordan Form)</a></li> </ul> </li> <li class="toc-entry toc-h2"> <a href="#9-%E5%AE%9E%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E7%AE%97%E5%AD%90">9 实向量空间中的算子</a> <ul> <li class="toc-entry toc-h3"><a href="#9a-%E5%A4%8D%E5%8C%96">9.A 复化</a></li> <li class="toc-entry toc-h3"><a href="#9b-%E5%AE%9E%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4%E4%B8%8A%E7%9A%84%E7%AE%97%E5%AD%90">9.B 实内积空间上的算子</a></li> </ul> </li> <li class="toc-entry toc-h2"><a href="#%E6%80%BB%E7%BB%93">总结</a></li> </ul> </div> <hr> <div id="markdown-content"> <p>本人在大一下就跟着卢老师学过 LinearAlgebraDoneRight 部分内容，现在快大四了基本都忘完了。不过该书优雅的架构和精巧的内容还是令我印象深刻，加上线性代数后面的内容我个人认为还是比较重要的，所以这个暑假我准备再看一遍并做些记录。本文可以看作我的拾遗，也可以当作本书我认为的重点内容和思路的回顾与整理。</p> <p><a href="https://link.springer.com/book/10.1007/978-3-319-11080-6" rel="external nofollow noopener" target="_blank">原书下载地址</a></p> <p>本文力图<strong>逻辑自洽</strong>、<strong>内容自洽</strong>，使读者走进线性代数，感觉到一个概念的引入和定义是<strong>自然</strong>的而不是<strong>突兀</strong>的，并能理解更深刻的内容，引导和理解的内容主要由我对原书作者的理解加工而成。</p> <h2 id="阅读本文原书可能的收获">阅读本文(原书)可能的收获</h2> <ul> <li>在线性映射框架下对特征值、特征向量的不同理解——第5章</li> <li>谱定理、奇异值分解的理论基础——第7章</li> <li>若当标准型——第8章</li> </ul> <h2 id="预备知识">预备知识</h2> <p>本文会直接从第五章，即特征值开始谈起，所以本章会先介绍常用记号和一些基础的概念，保持全文的完整性，便于阅读。当然，本章必然会不够完全，我会预设大家有一些线性代数、向量空间的知识比如向量空间定义，向量长成，向量空间的基与维数等，从而避免冗长的概念介绍。</p> <p>向量空间(vector space)：\(V, W\) 数域：\(F\)</p> <blockquote> <p>我认为这里的向量空间与经典线性代数教材的线性空间完全相同。</p> </blockquote> <p>子空间：含于原向量空间且运算封闭包含0元</p> <p>张成(span)：给定一组向量 \(v_1,\dots,v_m\)，\(\text{span}(v_1,\dots,v_m)=\{a_1v_1+\dots+a_mv_m\}\), 即由这些向量可以线性表示的所有向量的集合</p> <p>线性映射(linear map)：\(T:V\to W\)，满足</p> \[T(u+v)=T(u)+T(v), T(\lambda v)=\lambda T(v)\] <p>\(\mathcal{L}(V,W)\)：\(V\to W\)所有线性映射的集合，同样构成一个向量空间</p> <p>核空间(null space)：\(\text{null }T=\{v\in V:Tv=0\}\)</p> <p>像空间(range space)：\(\text{range }T=\{Tv:v\in V\}\)</p> <p>商空间(quotient space)：\(U\) 是 \(V\) 的子空间，那么商空间 \(V/U\) 定义 \(V/U=\{ v+U:v\in V \}\)</p> <blockquote> <p>核空间、像空间和商空间的概念在数学中使用是如此广泛以至于研究各种对象（向量空间、群）的映射时都会使用且放在一个重要地位。</p> </blockquote> <p>线性变换(linear transformation): 向量空间到自己的线性映射</p> <p>线性变换 \(T\) 复合 \(m\) 次记作 \(T^m\)，逆(如果可逆)记作 \(T^{-1}\)。特别的 \(T^0=I\)，即恒等映射。</p> <p>直和(direct sum)：设 \(U_1,\dots,U_,\) 是 \(V\) 的子空间，那么和 \(U_1+\dots+U_m\) 称为直和当每一个和空间的元素可以唯一写为 \(u_1+\dots+u_m,u_i\in U_i\). 我们用记号 \(U_1\oplus\dots\oplus U_m\) 来表示。</p> <p>对本文有兴趣却又对这些概念不熟悉的读者可以参看原书1-4章，相信上过线性代数课程的同学是不会感到陌生的。</p> <h2 id="5-特征值特征向量与不变子空间">5 特征值，特征向量与不变子空间</h2> <p>本章主要介绍有限维向量空间的线性变换，在不变子空间的基础上给出对于特征值、特征向量的理解和相关定理证明，我认为其思路不同于很多线性代数课本，是十分漂亮且有价值的。</p> <h3 id="5a-不变子空间">5.A 不变子空间</h3> <p>研究任何问题的方法都是先研究简单的情形，再考虑复杂的情况。那么想要理解线性变换，一个自然的思路就是考虑对向量空间进行降维，即分解成多个低维的空间，分而治之。假如我们有\(V\)的直和分解</p> \[V = U_1\oplus\dots\oplus U_m\] <p>那么这一目标就自然的完成了。然而事情没有那么简单，一个线性变换映射 \(U_i\) 中的元素最终不一定落在 \(U_i\) 中，那我们就没有办法将该变换仅限制在这个子空间(记为\(T\|_{U_i}\))，这也就自然的引出了不变子空间的定义：</p> <p><strong>定义5.A.1:不变子空间</strong>(invariant subspace)</p> <p>给定 \(T\in\mathbb{L}\)，一个向量空间 \(V\) 的子空间 \(U\) 称为不变子空间，若 \(u\in U\implies u\in Tu\).</p> <p>显然 \(V\) 本身，\(V\) 的核空间和像空间都是不变子空间，但它们并不一定能保证给我们不平凡的不变子空间。根据由简至繁的原则，我们下一步首先要研究的就是一维不变子空间，而这也就自然的引入了线性代数应用最广泛的概念之一——特征值与特征向量。</p> <p>相信读者可以自行写出一维不变子空间的情形，即 \(U=\{\lambda v:\lambda\in F\},v\ne0\) 且 \(Tv=\lambda v\)，这意味着我们将线性变换作用到该子空间的一个向量中，效果是伸长/缩短该向量的长度。这件事情并不平凡，足以让我们给他们一个单独取一个名字。</p> <p><strong>定义5.A.2：特征值</strong>(eigenvalue)，对应上文的 \(\lambda\)</p> <p><strong>定义5.A.3：特征向量</strong>(eigenvector)，对应上文的 \(v\)</p> <p>这是大家十分熟悉的概念了，不再详述定义。</p> <p><strong>定理5.A.1：对应不同特征值的特征向量是线性无关的</strong></p> <p>不难证明，对应不同特征值的特征向量是线性无关的（反证法+作用线性变化+使用不同特征值条件），也就告诉了我们有限维空间特征值的个数至多是空间维数多个。</p> <p>那么接下来一个自然的问题是，性质如此之好的一维不变子空间是不是总存在呢？这就引出了下一节的内容。</p> <h3 id="5b-特征向量与上三角矩阵">5.B 特征向量与上三角矩阵</h3> <p>为了回答上文的问题，我们需要一些多项式技术。</p> <p><strong>定义5.B.1:</strong> 线性变换的多项式</p> \[p(z)=a_0+a_1z+\dots+a_m z^m, z\in F\\ p(T)=a_0I+a_1T+\dots+a_m T^m, T\in \mathcal{L} \\ (pq)(T)=p(T)q(T)=q(T)p(T)\] <p>利用代数基本定理和刚才定义的线性变换的多项式我们就可以证明复向量空间的一个重要结论：</p> <p><strong>定理5.B.1:有限维非0的复向量空间上的线性变换一定有一个特征值</strong></p> <p>证明概要：考虑 \(v\in V,v\ne0\), 那么:</p> \[v,Tv,\dots,T^n v\] <p>必然线性相关，由代数基本定理可得</p> \[0=a_0v+\dots+a_n T^n v = c(T-\lambda_1I)\dots(T-\lambda_mI)v\] <p>推得 \(T\) 至少有一个特征值。</p> <blockquote> <p>代数基本定理的证明有许多方法，本人比较熟悉的是利用复变函数中的最大模原理。限于本文目的，不再多言。</p> </blockquote> <p>至此我们回答了特征值是否存在的问题，这是一件很重要的事情，为我们下面研究整个线性变化提供了强大的工具。在给出下一个结论前，我们需要回到线性变换的矩阵表示：</p> <p><strong>定义5.B.1：线性变换的矩阵\(\mathcal{M}(T)\)</strong></p> <p>若 \(T\in\mathcal{L}(V)\), \(v_1,\dots,v_n\) 是一组基。那么相对于这组基下 \(T\) 的矩阵表示就可以写为</p> \[\mathcal{M}(T)= \begin{pmatrix} A_{1,1}&amp;\dots&amp; A_{1,n}\\ \vdots &amp; &amp; \vdots\\ A_{n,1} &amp; \dots &amp; A_{n,n} \end{pmatrix}\] <p>其中 \(A_{j,k}\) 由下式定义</p> \[Tv_k=A_{1,k}v_1+\dots+A_{n,k}v_n\] <blockquote> <p>这实际上和线性映射的矩阵定义完全一致，第 \(i\) 列元素的取值实际上考虑如何将 \(Tv_i\) 在新的基下线性表示。这十分自然的告诉我们究竟该如何定义、理解矩阵乘法，感兴趣或者有困惑的读者可参阅原书第三章。</p> </blockquote> <p>研究一个线性变换可以一定程度上变成研究给定一组基下的矩阵。那么如何研究矩阵呢？我们的想法还是前文再三提到的由简至繁，一个自然的想法是矩阵越简单越好，即0元素越多越好。</p> <p>相信读者已经隐约有所感觉，我们在本章发展的工具一定程度上能回答这个问题了。一个特征向量 \(v\) 在 \(T\) 作用下不就是 \(\lambda v\) 吗，那这一列元素只有一个是 \(\lambda\) ，其他都是0，这也就带来了下一个重要定理：</p> <p><strong>定理5.B.2：有限维复向量空间线性变换 \(T\) 的矩阵在某个基下一定是上三角的</strong></p> <p>原书给了两个证明，后一个证明是我在写本节时才看的，感觉更加优雅且与本文上文更加契合，简述如下：</p> <p>对维数归纳。定理5.B.1告诉我们至少有一个特征向量和对应的不变子空间，记为 \(v_1,U\). 那么考虑商空间 \(T/U\)，有归纳假设知该商空间存在上三角矩阵，即</p> \[(T/U)(v_j+U)\in\text{span}(v_2+U,\dots,v_j+U),j=2,\dots,n\] <p>进而得到 \(Tv_j\in\text{span}(v_1,\dots,v_j)\).</p> <p>此时聪明的读者可能会有新的想法，如果 \(T\) 的特征值有空间维数多个，用这些特征向量作为基组成的矩阵每一列不就只有一个非0元了吗，这个矩阵就会更优美，这也就引出了下一节的内容：</p> <h3 id="5c-特征空间与对角矩阵">5.C 特征空间与对角矩阵</h3> <p>在介绍对角矩阵之前我们要先引入特征空间的概念（这个概念在后几章的内容中会启着至关重要的作用）：</p> <p><strong>定义5.C.1：特征空间 \(E(\lambda,T)\)</strong></p> <p>线性变换 \(T\) 有特征值 \(\lambda\) ，那么其对应的特征空间为</p> \[E(\lambda,T)=\text{null}(T-\lambda I)\] <p>即该空间包含了对应该特征值的所有特征向量。由定理5.A.1可知所有的特征空间构成了原空间的直和。下一个定理告诉了我们这与对角矩阵（上文提到的更优美的矩阵）的关系：</p> <p><strong>定理5.C.1：对角化矩阵的等价条件</strong></p> <p>给定空间 \(V\), 线性映射 \(V\), \(\lambda_1,\dots,\lambda_m\)为不相同的特征值。以下条件是等价的：</p> <ol> <li> <p>\(T\) 可对角化(即存在一组基下表示为对角矩阵)</p> </li> <li> <p>\(V\) 存在由 \(T\) 的特征向量组成的基</p> </li> <li> <p>存在 \(n\) 个一维子空间使得 \(V\) 为它们的直和</p> </li> <li> <p>\(V\) 为所有特征空间的直和</p> </li> <li> \[\dim V=\dim E(\lambda_1,T)+\dots+\dim E(\lambda_m,T)\] </li> </ol> <p>该定理的一个直接推论就是我们想要的结果，同时作为本章内容的收尾。</p> <p><strong>定理5.C.2：如果 \(T\) 有空间维数多个不同特征值，则 \(T\) 可对角化</strong></p> <h2 id="6-内积空间">6 内积空间</h2> <p>由于我预设读者具有线性代数的基础知识，本章的许多定义定理和方法如内积、规范正交基、Gram-Schmidt正交化等内容都将略去不表，只讲我觉得大家可能不知道的、我认为有趣的、与之后章节密切相关的内容。</p> <p><strong>定理6.1 Cauchy-Schwarz 不等式：\(\|\langle u,v\rangle\|\le\|u\|\|v\|\)</strong></p> <p>许多经典不等式都是该不等式的特例(如高中时代喜闻乐见的柯西不等式)，见原书6.17.</p> <p><strong>定义6.1：线性函数</strong> (linear functional)</p> <p>一个 \(V\) 上的线性函数是从 \(V\) 到 \(F\) 的线性映射。</p> <p>介绍这个定义的目的是引出我认为本章最有趣的结论：</p> <p><strong>定理6.2：里斯表示定理</strong> (Riesz Representation Theorem)</p> <p>有限维向量空间 \(V\) 下任何一个线性函数 \(\varphi\) 可以唯一表示成与某一个向量的内积，即</p> \[\varphi(v)=\langle v, u\rangle,\forall v\in V\] <p>将 \(v\) 写成某一组正交基的线性表示加上线性映射的性质可以很容易的证明该定理，故略去证明。</p> <p><strong>定义6.2 正交补</strong> (orthogonal complement)</p> <p>一个 \(V\) 中的子集的补由正交该子集所有向量的向量构成，即</p> \[U^{\perp}=\{v \in V:\langle v, u\rangle=0 ,\forall u \in U\}\] <p>联想到立体几何中的线面垂直和面面垂直，不难理解该概念。</p> <p>可以证明，子空间和它的补空间自然的构成了原空间的一个直和分解，由这个分解可以自然的定义出下面一个概念：</p> <p><strong>定义6.3 正交投影</strong> (orthogonal projection)</p> <p>\(v=u+w,u\in U, w\in U^{\perp}\), 记 \(P_Uv=u,P_{U^\perp}=w.\)</p> <p>关于正交补和正交投影的相关性质请有兴趣的读者参阅原书，书中列举的基本性质都是平凡的。</p> <p>正交投影其实和我们平常所感觉的投影的概念基本相同，即点在平面上的垂线段。我们都知道垂线段举例最短，这可以推广为如下定理：</p> <p><strong>定理6.3：垂线段最短定理</strong> (来自本人的命名…)</p> <p>假设 \(U\) 是一个 \(V\) 的有限维子空间，那么</p> \[\|v-P_Uv\|\le\|v-u\|\] <p>将 \(v\) 写成该空间和补空间的直和形式，证明是显然的。</p> <p><strong>定理6.4：舒尔定理</strong> (Schur’s Theorem)</p> <p>有限维复向量空间 \(V\) 中的线性变换 \(T\) 一定有相对于某组正交基的上三角矩阵。</p> <p>由定理5.B.2和我们熟知的Gram-Schmidt正交化过程可直接导出该结论。</p> <p>匆匆掠过本章，我们已经有了足够的工具开始下一章，也是我认为最有趣的一章内容的学习。</p> <h2 id="7-内积空间中的算子">7 内积空间中的算子※</h2> <p>这一章我们将详细研究内积空间中的算子，我们会看到大家平时经常听到的<strong>谱定理、奇异值分解</strong>在线性代数理论里的位置。</p> <blockquote> <p>从本章开始的内容应该是大部分读者没有接触过的了，难度和陌生度显著提升，我会适当增加摘要内容帮助<strong>我自己</strong>和读者的理解。如果你觉得对略去的证明和内容感兴趣或者觉得我讲的太跳，请参阅原书第7章，或者在评论中告知。</p> </blockquote> <blockquote> <p>算子基本上就是线性变换，从本章开始我大概率会使用算子(operator) 这个词，原因不明。</p> </blockquote> <h3 id="7a-伴随与正规算子">7.A 伴随与正规算子</h3> <blockquote> <p>这里的伴随和大家上课学到的伴随矩阵大概率没有关系。</p> </blockquote> <p><strong>定义7.A.1：伴随，\(T^*\)</strong> (adjoint)</p> <p>\(T\in\mathcal{L}(V,W)\) \(T\) 的伴随是 \(T^*: W\to V\) 使得</p> \[\langle Tv,w\rangle=\langle v, T^* w\rangle,\forall v\in V, \forall w\in W\] <p>伴随的存在性由里斯表示定理保证。</p> <p><strong>例7.A.1</strong></p> <p>固定 \(u\in V,x\in W\), 定义 \(T\in\mathcal{L}(L,W)\)</p> \[Tv=\langle v,u\rangle x\] <p>不难证明 \(T^*w=\langle w,x\rangle u\).</p> <p>伴随这个概念十分重要，是整章内容的基础。本文在此列出部分书中给出的有关伴随性质：</p> <ul> <li> <p>伴随本身构成了线性映射</p> </li> <li> \[(T^*)^*=T\] </li> <li> \[\text{null } T^*=(\text{range }T)^{\perp}\] </li> </ul> <p>既然伴随本身就是线性映射，那么一个自然的问题是它的矩阵表示跟原线性映射的矩阵表示有什么关系，而在内积空间中使用正交基显然更有可能使问题简化，于是我们有如下结论：</p> <p>\(T\in\mathcal{L}(V,W)\), \(e_1,\dots,e_n\) 是 \(V\) 中一组<strong>正交基</strong>， \(f_1,\dots,f_m\) 是 \(W\) 一组<strong>正交基</strong>，那么伴随的矩阵表示</p> \[\mathcal{M}\left(T^{*},\left(f_{1}, \ldots, f_{m}\right),\left(e_{1}, \ldots, e_{n}\right)\right)\] <p>是原矩阵表示的<strong>共轭转置</strong>(conjugate transpose).</p> \[\mathcal{M}\left(T,\left(e_{1}, \ldots, e_{n}\right),\left(f_{1}, \ldots, f_{m}\right)\right)\] <p>读者将两个矩阵每一项写出来即可证明该结论。</p> <p>考虑到我们的目的是研究算子，即线性变换而不是一般性的线性映射，所以我们考虑一种特殊的伴随，即该算子本身就是自己的伴随：</p> <p><strong>定义7.A.2 自伴算子</strong> (self-adjoint)</p> <p>若 \(T=T^*\), 即 \(\langle Tv,w\rangle=\langle v,Tw\rangle\)，则称算子 \(T\) 是自伴的</p> <blockquote> <p>有些书中自伴算子/矩阵表示又称为厄米算符/厄密矩阵(Hermitian matrix) ，这个词读者可能会更熟悉。</p> </blockquote> <p>在给出一个新的概念后我们自然要关注它的基本性质：</p> <p><strong>定理7.A.1 自伴算子的性质</strong></p> <ol> <li>自伴算子的特征值是实的 \(\lambda\|v\|^{2}=\langle\lambda v, v\rangle=\langle T v, v\rangle=\langle v, T v\rangle=\langle v, \lambda v\rangle=\bar{\lambda}\|v\|^{2}\)</li> <li>若自伴算子满足 \(\langle Tv,v\rangle=0,\forall v\)，那么 \(T=0\) 注意复内积空间下任何算子都满足该性质</li> <li>复内积空间下 \(T\) 是自伴的等价于 \(\langle Tv,v\rangle\in R\)</li> </ol> <p>自伴算子看起来就是一个很强的性质，它要求 \(T\) 和 \(T^*\) 是一回事。有些时候我们不需要这么强的版本，下面我们介绍一个稍微弱化的情况，即要求 \(T\) 和 \(T^*\) 是可交换的：</p> <p><strong>定义7.A.3 正规算子</strong> (normal)</p> <p>若算子 \(T\) 满足 \(TT^* = TT^*\)，则称算子 \(T\) 是正规的</p> <p>显然，自伴算子一定是正规的。</p> <p><strong>定理7.A.2 正规算子的性质</strong></p> <ol> <li> <p>\(T\) 是正规的当且仅当 \(\|Tv\|=\|T^*v\| \Longleftrightarrow T^*T-TT^*=0\\\Longleftrightarrow \langle(T^*T-TT^*)v,v\rangle=0\text{ 定理7.A.1(2)} \\ \Longleftrightarrow \langle T^*Tv,v\rangle=\langle TT^*v,v\rangle\\\Longleftrightarrow \|Tv\|=\|T^*v\|\)</p> </li> <li> <p>如果 \(T\) 是正规的，那么 \(T\) 与 \(T^*\) 有相同的特征向量和共轭的特征值 注意到 \(T-\lambda I\) 也是正规的，由(1)可直接推得结论</p> </li> <li> <p>正规算子下对应不同特征值的特征向量是正交的 \(Tu=\alpha u, Tv=\beta v\)，则由(1)知 \(T^*v=\bar\beta v\) \((\alpha-\beta)\langle u,v\rangle=\langle Tu,v\rangle-\langle u,\bar\beta v\rangle\) \(=\langle Tu,v\rangle-\langle u,T^*v\rangle=0\) 该性质十分重要，它实际上呼应了上下文特征向量同时正交的要求</p> </li> </ol> <p>如果读者对自伴算子和正规算子的概念和性质感到困惑和诧异，这是十分正常的，因为这两个概念与谱定理密不可分。所以请往下读。</p> <h3 id="7b-谱定理-the-spectral-theorem-">7.B 谱定理 (The Spectral Theorem) ※</h3> <p>从第五章的研究过程我们已经发现了，简化矩阵表示是十分重要的。第五章中的对角矩阵来自于由特征向量组成的基，那么在内积空间中我们自然会想使用正交基，那要是这些特征向量同时是正交向量的话，这个矩阵的性质就再好不过了。谱定理告诉我们这是可以做到的！</p> <p>当然，显然不是所有算子都有这么好的性质，而对算子性质的要求其实就是上一节我们讨论的正规算子(复数域)和自伴算子(实数域)。我们在上一章讨论的性质在以下两个定理的证明中会派上用场。</p> <p><strong>定理7.B.1 复谱定理</strong></p> <p>若 \(F=C, T\in V\), 那么下列条件是等价的：</p> <ol> <li> <p>\(T\) 是正规的</p> </li> <li> <p>\(V\) 中存在一组正交基构成 \(T\) 的特征向量</p> </li> <li> <p>\(T\) 存在相对于某组正交基的对角矩阵</p> </li> </ol> <p>证明概要：(2)与(3)显然等价。假设(3)成立，那么 \(T\) 与 \(T^*\) 都是对角矩阵，显然 \(TT^*=T^*T\)，\(T\) 是正规的，(1)成立。 假设(1)成立，根据第6章的舒尔定理，存在一组正交基使得矩阵表示为上三角矩阵，即</p> \[\mathcal{M}(T,(e_1,\dots,e_n))= \begin{pmatrix} a_{1,1} &amp; \dots &amp; a_{1,n}\\ &amp; \ddots &amp; \vdots \\ 0 &amp; &amp; a_{n,n} \end{pmatrix}\] <p>我们证明这个矩阵实际上是对角矩阵。由于</p> \[\|Te_1\|^2=|a_{1,1}|^2, \|T^*e_1\|^2=|a_{1,1}|^2+\dots+|a_{1,n}|^2\] <p>而 \(T\) 的正规性性质告诉我们 \(\|Te_1\|=\|T^*e_1\|\)，这就说明了第一行只有除了第一个元素都是0. 而在证明给 \(a_{1.2}=0\) 后，我们可以发现对于 \(Te_2\) 也可以用相同的方法证明第二行其他元素也都为0，重复该过程，即可证明定理。</p> <p>直觉来说线性代数中实数的性质不如复数，所以实谱定理要求的算子的性质也要更好，即要求自伴算子而不仅仅是正规算子。</p> <p>实谱定理的证明较为麻烦，需要一些引理且篇幅较长，其目的可以看作是给出实空间下自伴算子特征值和对于不变子空间（注意到复谱定理的简洁来自于舒尔定理，根属于代数基本定理保证了特征值存在）。 本文略过证明，仅述结论：</p> <p><strong>定理7.B.2 实谱定理</strong></p> <p>若 \(F=R, T\in V\), 那么下列条件是等价的：</p> <ol> <li> <p>\(T\) 是自伴的</p> </li> <li> <p>\(V\) 中存在一组正交基构成 \(T\) 的特征向量</p> </li> <li> <p>\(T\) 存在相对于某组正交基的对角矩阵</p> </li> </ol> <blockquote> <p>谱定理给出了有限维实/复内积空间算子可在正交基下对角化的充要条件，读者从原书部分习题中可以感受到谱定理的强大。</p> </blockquote> <p>读者在感叹谱定理的奇妙同时，可能也会想能不能有一种情况不需要什么算子条件也能得到对角矩阵。当然由谱定理的充要性我们知道这是不现实的。所以为了达成这个目的，我们要放弃一些东西——矩阵表示使用同一组基。</p> <p>注意到至此我们考虑的都是映射两端用相同的基，那么如果允许使用不同的基呢，我们能得到对角矩阵吗，用的基是我们所期待的内积空间的正交基吗？这也就是奇异值分解要告诉我们的。为此，我们同样需要一些基础的算子，即下一节：</p> <h3 id="7c-正算子与等距同构">7.C 正算子与等距同构</h3> <p>7.C, 7.D的架构看起来与7.A, 7.B十分相似，即定义特殊的算子，然后在这样满足一定性质的算子基础上叙述某一重要的定理。</p> <p><strong>定义7.C.1：正算子</strong> (positive operator)</p> <p>若 \(T\) 是自伴算子且满足 \(\langle Tv,v\rangle\ge0\), 则我们称 \(T\) 是正的 复内积空间下该定义的良性由定理7.A.1(3)保证。</p> <blockquote> <p>一些书中的半正定算子(positive semidefinite operator) 和正算子是一回事。</p> </blockquote> <p><strong>例7.C.1：投影算子是正算子</strong></p> <p><strong>定义7.C.2：平方根</strong> (square root)</p> <p>若算子 \(R^2=T\), 则称 \(R\) 是 \(T\) 的平方根</p> <p>类似的，我们也需要一些关于正算子和平方根的性质来帮助我们更好的理解这些概念：</p> <p><strong>定理7.C.1 正算子的性质</strong></p> <p>下列条件是等价的：</p> <ol> <li> <p>\(T\) 是正的</p> </li> <li> <p>\(T\) 是自伴且所有特征值非负 这告诉了我们正算子和自伴算子的联系</p> </li> <li> <p>\(T\) 有正平方根</p> </li> <li> <p>\(T\) 有自伴平方根</p> </li> <li> <p>存在算子 \(R\) 满足 \(T = R^*R\)</p> </li> </ol> <blockquote> <p>本节我可能会给出比较多的证明概要/内容，因为我自己忘得差不多了，再加上这些证明本身也较为自然和有用，读者可自行证明，也可看看本文概要，当然也可不管。</p> </blockquote> <p>证明概要： (1)推(2)是显然的。 (2)推(3)：由于 \(T\) 是自伴的，谱定理保证存在特征向量构成的正交基 \(e_1,\dots,e_n\) 和对应的特征值 \(\lambda_1,\dots,\lambda_n\), 非负保证了可定义 \(Re_j=\sqrt{\lambda_j}e_j\) ，不难证明 \(R\) 即是 \(T\) 的正平方根。 利用该方法不难推得正平方根是唯一的，记作 \(\sqrt{T}\). (3)推(4)是显然的。 (4)推(5)是显然的，因为自伴意味着 \(R^*R=R^2=T\). (5)推(1)：\(T^*=(R^*R)^*=R^*R=T\) 可知自伴，\(\langle Tv,v\rangle=\langle Rv,Rv\rangle\ge0\)</p> <p>另一方面，保持范数的算子十分重要，它值得一个单独的名字：</p> <p><strong>定义7.C.3：等距同构</strong> (isometry)</p> <p>若算子 \(S\in\mathcal{L}(T)\) 满足 \(\|Sv\|=\|v\|\)，则称 \(S\) 是等距同构</p> <p><strong>定理7.C.2 等距同构的性质</strong></p> <p>下列条件是等价的：</p> <ol> <li> <p>\(S\) 是等距同构</p> </li> <li> \[\langle Su,Sv\rangle = \langle u, v\rangle\] </li> <li> <p>\(V\) 的一组正交基在等距同构作用下依旧正交</p> </li> <li> \[S^*S=SS^*=I\] </li> <li>\(S^*\) 是等距同构</li> </ol> <p>证明概要： (1)推(2)：</p> \[\begin{aligned} \langle S u, S v\rangle &amp;=\left(\|S u+S v\|^{2}-\|S u-S v\|^{2}\right) / 4 \\ &amp;=\left(\|S(u+v)\|^{2}-\|S(u-v)\|^{2}\right) / 4 \\ &amp;=\left(\|u+v\|^{2}-\|u-v\|^{2}\right) / 4 \\ &amp;=\langle u, v\rangle \end{aligned}\] <p>(2)推(3)是显然的。 (3)推(4)：若有 \(e_1,\dots,e_n\) 正交基，那么</p> \[\langle S^*Se_j,e_k\rangle=\langle e_j,e_k\rangle=0,i\ne k\] <p>不难证明 \(S^*S\) 只能是 \(I\). (4)推(5)：注意到 \(\|S^*v\|^2=\langle SS^*v,v\rangle\) (5)推(1)：从(4)的对称性不难看出</p> <p>由该定理我们很容易可以证明下定理：</p> <p><strong>定理7.C.3 复内积空间下等距同构的描述</strong></p> <p>若 \(V\) 是复内积空间且 \(S\in\mathcal{L}(V)\)，那么 \(S\) 是等距同构当且仅当存在一组由 \(S\) 的特征向量构成的正交基，且特征值绝对值为1</p> <p>实内积空间下的情况要等到第9章我们才会回答。</p> <p>有了这些准备，我们最终可以开始本章最后一节内容：</p> <h3 id="7d-极分解polar-decomposition与奇异值分解-singular-value-decomposition-">7.D 极分解(Polar Decomposition)与奇异值分解 (Singular Value Decomposition) ※</h3> <p>经过漫长的旅程，我们终于快来到著名的<strong>奇异值分解</strong>。在此之前，我们先看看极分解是怎么一回事，它实际上告诉我们一个算子<strong>总是</strong>可以分解为等距同构和一个正算子的乘积：</p> <blockquote> <p>原书中的类比：复数 \(z\) 满足 \(z=(\frac{z}{\|z\|})\|z\|=(\frac{z}{\|z\|})\sqrt{\bar zz}\).</p> </blockquote> <p><strong>定理7.D.1 极分解</strong></p> <p>若 \(T\in\mathcal{L}(V)\) , 那么存在等距同构使得 \(S\in\mathcal{L}(V)\) 使得</p> \[T=S\sqrt{T^*T}\] <p>证明概要：</p> <ol> <li> \[\|Tv\|=\|\sqrt{T^*T}v\|\] </li> <li> <p>定义 \(S_1:\text{range }\sqrt{T^*T}\to\text{range }T\) 为 \(S_1(\sqrt{T^*T}v)=Tv\)，这是良定义的(利用(1))，是线性映射，是单射</p> </li> <li>考虑 \(\text{range}\sqrt{T^*T}^\perp\)，将 \(S_1\) 拓展至我们需要的 \(S\).</li> </ol> <p>因此我们可以将 \(V\) 上的<strong>任意</strong>算子写作两个算子的乘积(即正算子和等距同构)，而这两个算子又可以被我们完全理解。等距同构的描述由定理7.C.3给出，正算子的描述由谱定理给出。要注意的是在复域情况下正算子和等距同构都各自有一组正交基使其为对角矩2阵，但这两组基可能并不相同。</p> <blockquote> <p>上面这段话和下面一些话完全从原书翻译而来，因为我觉得写的真的很好！</p> </blockquote> <p><strong>定义7.D.1 奇异值</strong></p> <p>算子 \(T\) 的奇异值即即为 \(\sqrt{T^*T}\) 的特征值</p> <p>奇异值一定是非负的。注意每一个有限维空间上的算子都有维数多个奇异值(考虑重数)，这可以看作谱定理作用到正算子的结果。</p> <p>最后，我们要证明奇异值定理——每一个 \(V\) 上算子都可以用它的奇异值和两个。我们可以看到，之前的努力(谱定理，极分解及前面诸多概念定理) 是值得的：</p> <p><strong>定理7.D.2 奇异值分解</strong></p> <p>若 \(T\in\mathcal{L}(V)\) 有奇异值 \(s_1,\dots,s_n\)，那么存在正交基 \(e_1,\dots,e_n\) 和 \(f_1,\dots,f_n\) 使得</p> \[Tv=s_1\langle v,e_1\rangle f_1+\dots+ s_n\langle v,e_n\rangle f_n\] <p>证明：对 \(\sqrt{T^*T}\) 使用谱定理我们可以得到存在特征向量构成的正交基 \(e_1,\dots,e_n\) 满足 \(\sqrt{T^*T}e_j=s_je_j\), 由正交基的基本性质得到</p> \[v=\langle v,e_1\rangle e_1+\dots+\langle v,e_n\rangle e_n\] <p>等式两边作用 \(\sqrt{T^*T}\) 可以得到</p> \[\sqrt{T^*T} v = s_1\langle v,e_1\rangle e_1+\dots+s_n\langle v,e_n\rangle e_n\] <p>由极分解定理我们知道存在等距同构满足 \(T=S\sqrt{T^*T}\), 两边作用该算子我们得到（等距同构保持正交性）</p> \[Tv=s_1\langle v,e_1\rangle Se_1+\dots+ s_n\langle v,e_n\rangle Se_n\\=s_1\langle v,e_1\rangle f_1+\dots+ s_n\langle v,e_n\rangle f_n\] <p>Q.E.D.</p> <p>当我们在谈论算子时，我们总是习惯使用同一组基。而奇异值分解让我们可以很好的使用两个基来研究算子。接上文定义，因为 \(Te_j=s_if_j\), 我们可以发现</p> \[\mathcal{M}\left(T,\left(e_{1}, \ldots, e_{n}\right),\left(f_{1}, \ldots, f_{n}\right)\right)=\left(\begin{array}{ccc} s_{1} &amp; &amp; 0 \\ &amp; \ddots &amp; \\ 0 &amp; &amp; s_{n} \end{array}\right)\] <p>综上所述，奇异值分解回答了我们在7.B谱定理一节中提出的问题，即允许使用两组基从而使矩阵对角。而奇异值分解本身在各个领域也有着极大的应用，相信读者在今后碰到时不会陌生，能理解其理论基础。</p> <h2 id="8-复向量空间中的算子">8 复向量空间中的算子</h2> <p>本章我们回到复向量空间，考虑其上的算子结构。虽然我们没有了内积这一个强大的工具，但同样可以通过别的技术发展出一套强大的方法——若当标准型来描述算子的结构。</p> <p>简单来说，我们最终可以证明任意一个复线性空间的算子在某组基下都可以表示成对角块的形式，即</p> \[\begin{pmatrix} A_1 &amp; &amp; 0\\ &amp; \ddots &amp; \\ 0 &amp; &amp; A_p \end{pmatrix}\] <p>每一个块 \(A_j\) 都是如下形式的矩阵</p> \[A_j =\begin{pmatrix} \lambda_j &amp; 1 &amp; &amp; 0\\ &amp; \ddots &amp; \ddots &amp; \\ &amp; &amp; \ddots &amp; 1 \\ 0 &amp; &amp; &amp; \lambda_j\\ \end{pmatrix}\] <p>可以发现这个矩阵和我们理想的对角矩阵即为相近，为此我们有一段更漫长的路要走。首先，让我们回到并扩展第5章的核心概念——特征值/向量：</p> <h3 id="8a-广义特征向量与幂零算子">8.A 广义特征向量与幂零算子</h3> <p>从第5章我们可以知道，许多算子没有足够多的特征向量支撑成一组基，无法完成对任意给定算子 \(T\) 利用不变子空间进行降维，即</p> \[V=U_1\oplus\dots\oplus U_m\] <p>每一个 \(U_i\) 都是 \(T\) 一个不变子空间。最简单优雅的情况是每一个 \(U_i\) 都是一维的，这样我们可以自信的说我们完全搞清楚该算子的结构了。这种情况当且仅当 \(V\) 有一组由特征向量构成的基，当且仅当 \(V\) 有特征空间的直和分解，即</p> \[V = E(\lambda_1,T)\oplus\dots\oplus E(\lambda_m,T)\] <p>谱定理告诉我们内积空间下这样的分解在复数域下对正规算子存在，实数域下对自伴算子存在。然而这样的分解一般情况下不一定存在，考虑一个简单的例子：\(T(w,z)=(z,0)\)，读者可以自行验证。而广义的特征值和广义的特征空间可以解决这个问题。</p> <blockquote> <p>这几段话还是翻译原文的。</p> </blockquote> <p>我们知道特征向量是 \(T-\lambda I\) 的零点，那么一个自然的想法是略微改动这个式子，使得它能出现更多的零点。回想到核空间的概念，我们知道 \(0\) 映射后还是 \(0\)，而其他向量则有可能映射到 \(0\)，成为核空间的一部分。而在它们成为核空间的一部分之后，无论作用多少次映射，它都是核空间的一部分了。这段话其实是在说，我们可以讨论幂次映射的零点，这就引出了定义：</p> <p><strong>定义8.A.1：广义特征向量</strong> (generalized eigenvector)</p> <p>若 \(T\in\mathcal{L}(V)\) 且 \(\lambda\) 是 \(T\) 的一个特征值。那么若向量 \(v\) 满足</p> \[(T-\lambda I)^jv=0, j\in N^+\] <p>我们称 \(v\) 是 \(T\) 的广义特征向量。(为什么我们不需要广义特征值呢？) 相应的，\(G(\lambda,T)\) 即为广义特征空间。</p> <p>在继续之前，我们需要简单讨论一下核空间在幂次下的性质，总结如下：</p> <p><strong>定理8.A.1：幂次算子下的核空间性质</strong></p> <ol> <li> \[\{0\}=\text{null }T^0\subset\text{null }T^1\subset\dots\subset\text{null }T^k\subset\dots\] </li> <li> <p>\(n\) 为空间维数，那么 \(\text{null }T^n=\text{null }T^{n+1}=\dots\)</p> </li> <li> \[V=\text{null }T^n\oplus\text{range }T^n\] </li> </ol> <p>这告诉我们 \(G(\lambda,T)=\text{null }(T-\lambda I)^{\dim V}\).</p> <p>我们知道对应不同特征值的特征向量之间线性无关，这是一切的基础，因为只有这样才有可能组成一组基。那么广义特征向量自然也要满足：</p> <p><strong>定理8.A.2：对应于不同特征值的广义特征向量线性无关</strong></p> <p>证明略</p> <p>幂次最终为0的算子也很重要，它值得一个名字：</p> <p><strong>定义8.A.2：幂零算子</strong> (nilpotent)</p> <p>若一个算子的某个幂次为0，我们称该算子为幂零算子</p> <p>不知道读者是否发现，我们在给出一个算子后经常要讨论它的矩阵表示，幂零算子也是如此。</p> <p><strong>定理：8.A.3：幂零算子的矩阵表示</strong></p> <p>若 \(N\) 为幂零算子，则存在一组基使得 \(N\) 矩阵表示为对角线为0的上三角矩阵：</p> \[\begin{pmatrix} 0 &amp; &amp; * \\ &amp; \ddots &amp; \\ 0 &amp; &amp; 0 \end{pmatrix}\] <p>证明概要：首先选择 \(\text{null }N\) 的一组基，然后扩展成 \(\text{null }T^2\) 的一组基，直至扩展成 \(\text{null }N^{\dim V}\) 的一组基(\(\text{null }N^{\dim V}=V\)). 不难证明，这组基下的矩阵就是符合要求的。</p> <h3 id="8b-算子的分解">8.B 算子的分解</h3> <p>正如上一节所言，本节我们会看到每一个有限维复向量空间上的算子都有足够的广义特征向量能构成直和分解。</p> <p><strong>定理8.B.1</strong></p> <p>若 \(T\) 是 \(V\) 是复向量空间内算子，\(\lambda_1,\dots,\lambda_m\) 为所有不同的特征值，那么</p> <ol> <li> \[V= G(\lambda_1,T)\oplus\dots\oplus G(\lambda_m,T)\] </li> <li> <p>每一个 \(G(\lambda_j,T)\) 在 \(T\) 下是不变的</p> </li> <li>每一个 \((T-\lambda_j I)\|_{G(\lambda_j,T)}\) 是幂零的</li> </ol> <p>证明：(2)与(3)由 \(G(\lambda_j,T)=\text{null }(T-\lambda_j I)^n\) 是显然的。我们通过数学归纳法证明(1). \(n=1\) 是显然的。</p> <p>\(n&gt;1\) 时，复向量空间保证了至少有特征值 \(\lambda_1\) 的存在，由定理8.A.1(3)我们知道 \(V=G(\lambda_1,T)\oplus U,U=\text{range}(T-\lambda_1 I)^n\). 不难证明 \(U\) 在 \(T\) 作用下是不变的，由归纳假设 \(U=G(\lambda_2,T\|_U)\oplus\dots\oplus G(\lambda_m,T\|_{U})\)，读者不难根据广义特征向量线性无关证明 \(G(\lambda_k,T)\subset G(\lambda_k,T\|_U)\)，从而推得 \(G(\lambda_k,T)= G(\lambda_k,T\|_U)\).</p> <p>定理8.B.1(1)告诉我们了存在足够的广义特征向量来张成整个空间。</p> <p><strong>定义8.B.1：重数</strong></p> <p>特征值的重数为对应广义特征空间的维数</p> <blockquote> <p>我们常用的代数重数即为这里的重数，为广义特征空间的维数</p> <p>而几何重数则是特征空间的维数</p> </blockquote> <p>那么一个自然的问题是，这个结论之下的矩阵表示是怎么样的呢？ 其实已经可以看出来了。 \(V\) 能分解成广义特征空间的直和，所以会有对角块的形式，每一个块 \(T|_{G(\lambda_j,T)}=(T-\lambda_j I)|_{G(\lambda_j,T)}+\lambda_j I|_{G(\lambda_j,T)}\) 即为一个幂零算子和单位矩阵的加和，即</p> \[A_{j}=\left(\begin{array}{ccc} \lambda_{j} &amp; &amp; * \\ &amp; \ddots &amp; \\ 0 &amp; &amp; \lambda_{j} \end{array}\right)\] <p>可以发现和本章引言的约当型还是有些区别的，不过这个结论也足够强大，而且是后面简化的基础。</p> <h3 id="8c-特征多项式和极小多项式">8.C 特征多项式和极小多项式</h3> <blockquote> <p>本节仅述一小部分</p> </blockquote> <p><strong>定义8.C.1：特征多项式</strong></p> <p>若 \(V\) 是复向量空间，假设 \(\lambda_1,\dots,\lambda_m\) 是算子 \(T\) 的不同特征值，重数分别是 \(d_1,\dots,d_m\). 那多项式 \((z-\lambda_1)^{d_1}\dots(z-\lambda_m)^{d_m}\) 就称为 \(T\) 的特征多项式。</p> <p><strong>定理8.C.1：凯莱-哈密顿定理</strong> (Cayley-Hamilton Theorem)</p> <p>设 \(q\) 是复向量空间中算子 \(T\) 的特征多项式，那么 \(q(T)=0\).</p> <p>证明留给读者，可将其作为上节定理8.B.1的应用。</p> <h3 id="8d-约当型-jordan-form">8.D 约当型 (Jordan Form)</h3> <p>8.B告诉我们每一个复向量空间的算子都有一组基使其构成一个不错的矩阵。这节，即本章的最后一节我们将会证明我们可以做得更好。</p> <p>8.B节我们证明了每一个对角块块 \(\|_{G(\lambda_j,T)}=(T-\lambda_j I)\|_{G(\lambda_j,T)}+\lambda_j \|_{G(\lambda_j,T)}\) 即为一个幂零算子和单位矩阵的和，单位矩阵已经是最简单的了，所以一个自然的想法是对于幂零算子，我们能不能做得更好，下面的定理告诉我们这是可以做到的：</p> <p><strong>定理8.D.1</strong></p> <p>若 \(N\) 是幂零的，那么存在一组向量 \(v_1,\dots,v_n\) 和非负整数 \(m_1,\dots,m_n\) 使得：</p> <ol> <li> <p>\(N^{m_1}v_1,\dots,Nv_1,v_1,\dots,N^{m_n}v_n,\dots,Nv_n,v_n\) 是一组基</p> </li> <li> \[N^{m_1+1}v_1=\dots=N^{m_n+1}v_n=0\] </li> </ol> <p>证明：我们对 \(\dim V\) 使用数学归纳法，\(\dim V=1\) 的时候显然成立。现假设 \(\dim V&gt;1\).</p> <p>因为 \(N\) 是幂零的，所以它既不是单射也不是满射，所以我们对 \(N\|_{\text{range }N}\) 使用归纳假设，可以得到</p> \[N^{m_1}v_1,\dots,Nv_1,v_1,\dots,N^{m_n}v_n,\dots,Nv_n,v_n\] <p>是 \(\text{range }N\) 的一组基且</p> \[N^{m_1+1}v_1=\dots=N^{m_n+1}v_n=0\] <p>而 \(v_j=Nu_j\)，所以 \(N^{k+1}u_j=N^kv_j\)，我们断言：</p> \[N^{m_1+1}u_1,\dots,Nu_1,u_1,\dots,N^{m_n+1}u_n,\dots,Nu_n,u_n (1)\] <p>是线性无关的。将上述向量张成一组基</p> \[N^{m_1+1}u_1,\dots,Nu_1,u_1,\dots,N^{m_n+1}u_n,\dots,Nu_n,u_n,w_1,\dots,w_p\] <p>\(Nw_i\in\text{range }N\)，故存在 \(x_i\in\text{span }(1),Nw_j=Nx_j\)，我们令 \(u_{n+j}=w_j-x_j\)，那么 \(Nu_{n+j}=0\)，不难发现</p> \[N^{m_1+1}u_1,\dots,Nu_1,u_1,\dots,N^{m_n+1}u_n,\dots,Nu_n,u_n,u_{n+1},\dots,u_{n+p}\] <p>即构成了一组基，又能满足我们的要求。Q.E.D.</p> <blockquote> <p>这个证明感觉有点玄妙，对于幂零算子性质利用的很好</p> </blockquote> <p>那么，这组基的矩阵是怎样的呢，对于每一个子块，算子 \(N\) 都把某一个基向量映射到这列的前一个，\(0,N^{m_j}v_j,\dots,Nv_j,v_j\)，其矩阵表示我们可以直接写出</p> \[\left(\begin{array}{cccc} 0 &amp; 1 &amp; &amp; 0 \\ &amp; \ddots &amp; \ddots &amp; \\ &amp; &amp; \ddots &amp; 1 \\ 0 &amp; &amp; &amp; 0 \end{array}\right)\] <p>联系到前面8.A.1我们就证明的结论，到这我们就给出了目前可达的复向量空间任一算子的最简矩阵表示——约当型，具体型式可见本章开头。</p> <h2 id="9-实向量空间中的算子">9 实向量空间中的算子</h2> <p>终于，我们来到本文的最后一章。本章我们会使用我们在复向量空间的结果来分析实向量空间。注意到不变子空间在线性代数中起着至关重要的作用，非0有限维复向量空间的每一个算子都有一个特征值从而有一维不变子空间，而实向量空间则有可能不存在特征值因此不存在一维不变子空间，所以下一节我们会介绍如何让实向量空间也有一个较简单的不变子空间。</p> <blockquote> <p>本章会较为简略。</p> </blockquote> <h3 id="9a-复化">9.A 复化</h3> <p>既然复空间有这么多好处，那么我们有什么办法让实空间也有这些好处呢？本节将会介绍一个自然的将实空间嵌入复空间的方法：复化。</p> <p><strong>定义9.A.1：向量空间的复化</strong></p> <p>若 \(V\)是一个实向量空间</p> <ul> <li>\(V\) 的复化记作 \(V_C\)，等价于 \(V\times V\)，我们一般写作 \(u+iv\)</li> <li> \[(u_1+iv_1)+(u_2+iv_2)=(u_1+u_2)+i(v_1+v_2)\] </li> <li> \[(a+bi)(u+iv)=(au-bv)+i(av+bu)\] </li> </ul> <p>联系到\(i^2=-1\)，乘法的定义就不难理解了，不难证明 \(V_C\) 是复向量空间，\(V\) 的一组基也是 \(V_C\) 的一组基，故其维数相同。</p> <p><strong>定义9.A.2：算子的复化</strong></p> <p>若 \(V\) 是实向量空间，\(T\in\mathcal{L}(V)\)，算子 \(T\) 的复化，记作 \(T_C\) 由下式定义： \(T_C(u+iv)=Tu+iTv\) 接下来则是本节的核心结论，也是复化最大的好处和意义：</p> <p><strong>定理9.A.1：每一个算子都有1维或2维不变子空间</strong></p> <p>复向量空间的情况是显然的。</p> <p>若 \(V\) 是实向量空间，则复化算子 \(T_C\) 一定有特征值 \(a+bi\)，那么存在 \(u,v\ne0\)： \(T_C(u+iv)=(a+bi)(u+iv)\\ Tu+iTv=(au-bv)+(av+bu)i\\ Tu=au-bv,Tv=av+bu\) 令 \(U\) 为 \(u,v\) 张成的空间，不难证明 \(U\) 即为一维或二维的不变子空间。下一节我们会看到这究竟有什么具体的好处。</p> <h3 id="9b-实内积空间上的算子">9.B 实内积空间上的算子</h3> <p>现在让我们把注意力放回到内积空间。复谱定理完全给出了复内积空间上正规算子的结构，本节我们将会描述清楚实内积空间的正规算子的结构，让我们从2维实向量空间开始：</p> <p><strong>定理9.B.1</strong></p> <p>若 \(V\) 是2维实内积空间，那么下列条件是等价的：</p> <ol> <li> <p>\(T\) 是正规的但不是自伴的</p> </li> <li> <p>\(T\) 相对于所有正交基的矩阵表示是如下形式： \(\begin{pmatrix} a &amp; -b\\ b &amp; a \end{pmatrix},b\ne0\)</p> </li> <li> <p>\(T\) 相对于某族正交基的矩阵表示是如下形式： \(\begin{pmatrix}a &amp; -b\\b &amp; a\end{pmatrix},b&gt;0\) 证明留给读者。</p> </li> </ol> <p>下一个定理告诉我们限制在不变子空间上的正规算子还是正规的，这给我们最后的定理的归纳法埋下了伏笔：</p> <p><strong>定理9.B.2</strong></p> <p>若 \(V\) 是内积空间， \(T\) 是正规算子，\(U\) 是 \(T\) 下不变子空间，那么</p> <ol> <li>\(U^\perp\) 是 \(T\) 下不变子空间</li> <li>\(U\) 是 \(T^*\) 下不变子空间</li> <li> \[(T\|_U)^*=(T^*)\|_U\] </li> <li>\(T\|_U\) 和 \(T\|_{U^\perp}\) 是正规算子</li> </ol> <p>证明概要：</p> <ol> <li> <p>利用 \(\|Te_j\|=\|T^*e_j\|\)，证明与复谱定理类似</p> </li> <li> <p>由(1)可立即得到</p> </li> <li>令 \(S=T\|_U，v\in U\), \(\langle Su,v\rangle=\langle Tu,v\rangle=\langle u,T^*v\rangle\)，而 \(T^*v\in U\)，也就说明了结论</li> <li>由(1-3)可立即得到</li> </ol> <p>来到了我们的最后一个目标：</p> <p><strong>定理9.B.3</strong></p> <p>若 \(V\)是实内积空间，\(T\) 是其上一个算子，那么下列条件等价：</p> <ol> <li>\(T\) 是正规的</li> <li>存在一组正交基使得 \(T\) 是块对角矩阵，且每个块是\(1\times1\)或者 \(\begin{pmatrix}a &amp; -b\\\\b &amp; a\end{pmatrix},b&gt;0\)</li> </ol> <p>证明：假设(2)成立，通过矩阵乘法可以立即验证 \(T\) 是正规的</p> <p>假设(1)成立，我们使用数学归纳法证明结论。\(\dim V=1\) 是平凡的，\(\dim V=2\) 由定理9.B.1和实谱定理保证。</p> <p>\(\dim V&gt;2\)，由定理9.A.1我们知道一定存在一维或二维不变子空间 \(U\). 若是1维的，即对应了 \(1\times1\)的矩阵，若是2维，则我们可以选择一组正交基使得它是上述要求的矩阵。</p> <p>注意 \(U^\perp\) 是 \(T\) 下不变子空间而且限制在上面还是正规算子(定理9.B.2)，由归纳假设我们知道，我们已经证完了。这也就完成了本章的目标。</p> <p>读者可自行根据该定理推导实内积空间上等距同构的结构，由等距不难猜出 \(a,b\) 需要对应旋转，即 \(\sin,\cos\)。</p> <h2 id="总结">总结</h2> <p>线性代数的核心在于研究线性映射和算子的结构。本书围绕这一核心展开，对多种情况进行了讨论，发现总是可以在某些限制条件下找到某组基分解简化算子结构，使其矩阵表示有更多的0。最后让我们通过下表回顾一下我们走过的定理，言尽于此…</p> <table> <thead> <tr> <th>空间</th> <th>数域</th> <th>条件</th> <th>定理</th> <th>结论</th> </tr> </thead> <tbody> <tr> <td>向量空间</td> <td>/</td> <td>足够特征向量</td> <td>5.C.1</td> <td>对角矩阵</td> </tr> <tr> <td>内积空间</td> <td>\(C\)</td> <td>正规算子</td> <td>复谱定理</td> <td>对角矩阵</td> </tr> <tr> <td>内积空间</td> <td>\(R\)</td> <td>自伴算子</td> <td>实谱定理</td> <td>对角矩阵</td> </tr> <tr> <td>内积空间</td> <td>/</td> <td>两组基</td> <td>奇异值分解</td> <td>对角矩阵</td> </tr> <tr> <td>向量空间</td> <td>\(C\)</td> <td>/</td> <td>8.B.1, 8.D.1</td> <td>约当型</td> </tr> <tr> <td>内积空间</td> <td>\(R\)</td> <td>正规算子</td> <td>9.B.3</td> <td>1, 2块对角矩阵</td> </tr> </tbody> </table> <hr> <div> <center>※※※ 完结撒花！※※※</center> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Qi Zhan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: January 02, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>