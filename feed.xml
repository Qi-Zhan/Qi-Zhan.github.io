<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://qi-zhan.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://qi-zhan.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-10-13T04:04:28+00:00</updated><id>https://qi-zhan.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">软件工程技术漫谈(1) —— 训练谜云</title><link href="https://qi-zhan.github.io/blog/2025/roundoff/" rel="alternate" type="text/html" title="软件工程技术漫谈(1) —— 训练谜云"/><published>2025-10-13T00:00:00+00:00</published><updated>2025-10-13T00:00:00+00:00</updated><id>https://qi-zhan.github.io/blog/2025/roundoff</id><content type="html" xml:base="https://qi-zhan.github.io/blog/2025/roundoff/"><![CDATA[<h3 id="缘起">缘起</h3> <p>2021年, 随着深度学习日益强大(<del>传统科研做不下去了</del>), 小z同学也被迫加入了炼丹大军. 虽然小z之前从来没写过相关代码, 好在实验室硬件条件不错, 有8张A800GPU. 经过一番(痛苦的)环境配置和神经网络速成, 小z也成功搞定, 开始了调参大业.</p> <p>好景不长, 新进组的师弟也要进行类似的科研工作, 也需要一半的卡. 如果小z只能使用一半的显存, 那么小z就需要减少一半batch size, 时间增加一倍问题倒不大, 反正闲着也是闲着. 然而在实验中, 小z发现一个大问题: 由于配置的不同, 之前调参得到的实验结果都要在新的batch size下重跑一遍, 甚至原来他以为的优化方法似乎在新的batch size下也并没有显著提升.</p> <p>这是很正常的事情, 毕竟深度学习即使是完全一样的配置都有可能运行出不同的结果, 何况是修改了batch size这种影响较大的操作. 但是小z也实在不想重新跑一遍所有参数下的代码, 于是想到了一个办法, 也就是<strong>梯度累计</strong>: 每次迭代之后不立即更新参数, 而是把多个小 batch 的梯度累加起来, 然后再进行一次梯度更新. 这样既可以减少需要的显存, 又在<strong>理论上</strong>可以得到与原来相同的结果. 为了确认这件事, 小z做了个实验, 把两个batch size的loss曲线都画出来对比, 如下图所示:</p> <p><img src="/assets/img/loss.png" alt="144804002-fbd31936-c58a-45c4-a991-5eabcde42f16"/></p> <p>虽然最终收敛的结果区别不大, 但是开启了梯度累计时loss曲线一度<strong>明显高于</strong>没有开启的时候, 而照理来说这两条曲线应该几乎完全一致, 难道说官方的代码有bug? 出于好奇心小z还是在PyTorch平台上提出了相关的issue, 得到的解释是浮点数的<strong>舍入误差</strong>会影响计算, 所以这两条曲线都是“合理”的.</p> <p>死去的关于浮点数的记忆开始攻击小z, 由于计算机硬件存储是有限的, 为了效率和可行性在存储实数时大多只存储一个近似的值, 而浮点数则是一种存储尾数和指数的方式, 广泛使用于计算机系统中, 自然也包括深度学习计算. 由于是近似的, 那么在存储和计算的过程之中就不可避免引入误差, 导致原本数学上等价的事情在浮点数世界不在等价. 例如加法的结合律在浮点数种就不再成立. 因此在比较不同有浮点数参与的算法时, 一般不会要求比特级别的相等, 而是允许一个界限(thereshold).</p> <p>理清这些, 确实存在一种可能: 由于开启了梯度累积时具体的计算过程和顺序不同, 导致浮点数的误差逐渐累计放大, 最终影响了整个loss. 但是这一点点浮点数的误差能累积到这个程度吗, 这个差异是能够接受的吗? 小z心里还是觉得非常疑惑, 不过反正最终收敛到的 loss 和测试集的准确率也差不多, 小z也就放下了这个疑问, 不再追问.</p> <p>而在3年之后的2024年, 小z突然发现自己当时的issue被人重新提起, 而且确认了这的确是由于<strong>代码实现的bug</strong>引起的, 而不是所谓的浮点数误差. 小z大概看懂了是计算最后loss的时候需要求平均除以batch size, 而实际上代码实现的分别是 \(\frac{a}{b} + \frac{c}{d}\) 与 \(\frac{a+c}{b+d}\). 在 \(b\) 和 \(d\) 很接近, 即多次梯度下降时有效的batch size很接近时, 这两个值很接近, 也就看不出什么不同. 而当有效batch size差异很大时, loss 也就出现了较大差异. 总而言之, 这确实是代码实现的bug, 导致在使用/不使用梯度累计时的数学公式实际上是不等价的.</p> <p>聪明的小z开始思考一个<strong>更深刻</strong>的问题: 这个问题更抽象一层来看是舍入误差和实现bug的<strong>分类</strong>问题. 现在存在一个标准实现(不开启梯度累积)和一个我们自己的优化实现(开启梯度累积), 在某一组输入下发现最终结果(loss)出现偏差. 由于浮点数误差的存在, 偏差是正常的, <strong>但是这种偏差究竟是由于实现bug导致的, 还是纯粹来自于舍入误差呢</strong>?</p> <p>(以上故事根据<a href="https://unsloth.ai/blog/gradient">真实事件</a>瞎编)</p> <h3 id="解决">解决</h3> <p>我们今年的一项工作既是围绕这一问题展开. 正如上文所说, 我们的目标是在深度学习背景下对于误差来源的二元分类. 如果是由于舍入误差(Type-I), 开发者可以调整thereshold 或者使用更高精度的浮点数, 而如果是由于实现bug(Type-II), 那么开发者就应该去修复这个问题.</p> <p>我们的思路是估计一个<strong>最大可能的舍入误差范围</strong>, 如下图所示: 对于我们的目标程序, 我们估计它输出可能的最大上界与最小下界. 如果参考实现的输出结果在这个界限之内, 那么我们就认为这是 Type-I 舍入误差. 反之, 我们就认为这是 Type-II 实现 bug.</p> <p><img src="/assets/img/approach.png" alt="image-20251013101052076"/></p> <p>那么怎么估计一个可能的误差呢, 我们使用了古典的区间算术技术. 简单来说, 对于一个数 \(a\) 我们用一个区间 \([\underline{a}, \overline{a}]\) 来表示其可能的范围, 在原程序运行过程中, 我们用区间上的计算来动态估计每个运行结果可能的上下界. 对于加法和乘法举例如下:</p> \[\begin{align*} [\underline{a}, \overline{a}] + [\underline{b}, \overline{b}] &amp; = [\underline{a} + \underline{b}, \overline{a} + \overline{b}], \\ [\underline{a}, \overline{a}] \times [\underline{b}, \overline{b}] &amp; = [\min(\underline{ab}, \underline{a} \overline{b},\overline{a} \underline{b}, \overline{ab}), \max(\underline{a} \underline{b}, \underline{a} \overline{b}, \overline{a} \underline{b}, \overline{ab})] \end{align*}\] <p>而在最后, 我们自然就得到了最终输出的上下界, 与参考程序输出的比较后也就完成了分类.</p> <p>(更多细节欢迎感兴趣的读者参考<a href="https://xing-hu.github.io/assets/papers/ASE2025zq.pdf">我们的论文</a>)</p> <h3 id="后文">后文</h3> <p>这一问题最早的提出来源于和我们组合作的企业, 他们和我讲了这个梯度累积的例子, 但是我就觉得这应该是一个挺有趣且实际的问题. 整体的技术在我看来是比较简单的, 区间算术是古典的不能再古典的技术了, 而我们是在深度学习背景下对 tensor 级别的区间计算重新发扬了一部分. 实验部分最麻烦的是数据集的收集, 因为这不像是bug检测任务有十分明确的标准和数据集, 我们在一些仓库扒了很多issue才拿到20几个数据进行验证. 虽然最后审稿时一个审稿人还是觉得我们是在做bug检测 :), 一个审稿人觉得由于条件数问题我们无法sound的估计误差:), 但他们还是慷慨的给了个大修, 也让这篇论文最后得以录用.</p> <p>我以前看过jyy 老师知乎的<a href="https://www.zhihu.com/column/se-research">软件工程技术漫谈</a>, 觉得这是很不错的分享工作的模式, 这才有了本篇内容. 后续如果我们也有我个人觉得有趣的工作, 也会继续通过该方式分享.</p>]]></content><author><name>[&quot;詹奇&quot;]</name></author><category term="cs"/><summary type="html"><![CDATA[缘起]]></summary></entry><entry><title type="html">浮点数，误差估计与分析</title><link href="https://qi-zhan.github.io/blog/2025/floating/" rel="alternate" type="text/html" title="浮点数，误差估计与分析"/><published>2025-02-11T00:00:00+00:00</published><updated>2025-02-11T00:00:00+00:00</updated><id>https://qi-zhan.github.io/blog/2025/floating</id><content type="html" xml:base="https://qi-zhan.github.io/blog/2025/floating/"><![CDATA[<p>众说周知，由于内存的有限，计算机只能通过近似的方法表示一般的实数。其中最为广泛使用的方法就是浮点数。本文介绍浮点数的表示方法，重点放在对其误差的分析和理解上。本文的诞生来自于个人科研需要的总结，势必无法面面俱到。</p> <h2 id="定义">定义</h2> <p>所谓浮点数表示，就是一种编码(近似)实数的方式，它通过尾数和幂数来表示：</p> \[\underbrace{d_0.d_1\dots d_{m-1}}_{尾数} \times \overbrace {\beta^e} ^{指数}\] <p>这里的 \(m\) 和 \(e\) 都是有限的（有固定的存储位数)，也就导致一些数字只能使用近似的方式存储。我们只关注基数为2的情况，即假设 \(\beta = 2\)。这里列出 IEEE 754 规定的一些浮点数类型以及表示尾数：</p> <table> <thead> <tr> <th> </th> <th>符号位</th> <th>指数</th> <th>尾数</th> </tr> </thead> <tbody> <tr> <td>half precision</td> <td>1</td> <td>5</td> <td>10</td> </tr> <tr> <td>single precision</td> <td>1</td> <td>8</td> <td>23</td> </tr> <tr> <td>double precision</td> <td>1</td> <td>11</td> <td>52</td> </tr> </tbody> </table> <h2 id="相对误差与-ulp">相对误差与 ULP</h2> <blockquote> <p>参考 [1] 1.2节。</p> </blockquote> <p>由于误差天然的存在于浮点数运算之中，找到一种衡量误差的方式就尤为重要。一种显然的方式是相对误差，也就是 \(\frac{x - \hat{x}}{x}\).</p> <p>而另一种衡量误差的方式源自于其表示内部。考虑 \(1.d_1d_2\dots d_m \times 2^e\), 这一表示对应的实数实际上可能是 \(1.d_1d_2\dots d_m 1 \times 2^e\), 而由于浮点数表示的性质，这一被忽略了。不难发现，这会导致 1 个单位的误差，也就是 unit in the last place (ULP), 在上述例子中也就是 \(2^{-m + e}\).</p> <p>一个有趣的事实是如果 ULP 误差会 bound 住相对误差, 那么有相对误差 \(\frac{x - \hat{x}}{x} \le k \epsilon, \epsilon=2^{-m}\), 证明如下：</p> <p>考虑正数 \(x\) 与其浮点数表示 \(1.d_1d_2\dots d_m \times 2^e\), ULP 为 \(0.00\dots01\), 那么有 \(\begin{aligned} |x - \hat{x}| \le k \epsilon &amp;= k 2^{-m + e} \\ \frac{x-\hat{x}}{x} &amp; \le \frac{k 2^{-m + e}}{x} \\ &amp;\le \frac{2^{-m}}{1.d_1d_2\dots d_m} \le 2^{-m} \end{aligned}\) 这表明了 ULP 误差实际上限制的是相对误差而不是绝对误差。</p> <p>我们列出常见浮点数类型的 1ULP 对应的误差 ( \(\epsilon\) ) [3].</p> <table> <thead> <tr> <th style="text-align: center">Common name</th> <th style="text-align: center">Precision</th> <th style="text-align: center">Rounding machine epsilon</th> <th style="text-align: center">Interval machine epsilon</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">half precision</td> <td style="text-align: center">11 (one bit is implicit)</td> <td style="text-align: center">2−11 ≈ 4.88e-04</td> <td style="text-align: center">2−10 ≈ 9.77e-04</td> </tr> <tr> <td style="text-align: center">single precision</td> <td style="text-align: center">24 (one bit is implicit)</td> <td style="text-align: center">2−24 ≈ 5.96e-08</td> <td style="text-align: center">2−23 ≈ 1.19e-07</td> </tr> <tr> <td style="text-align: center">double precision</td> <td style="text-align: center">53 (one bit is implicit)</td> <td style="text-align: center">2−53 ≈ 1.11e-16</td> <td style="text-align: center">2−52 ≈ 2.22e-16</td> </tr> </tbody> </table> <h2 id="误差分析">误差分析</h2> <p>本节我们讨论在浮点数误差框架下，基本运算，复合运算以及求和与矩阵乘法的误差估计。</p> <h3 id="基本运算">基本运算</h3> <p>我们实际使用的各种库对例如加法，乘法和基本的数学运算都有基于 ULP 的相对误差界限规范，例如 GNU C 库中要求这些运算的相对误差小于 2 ULP [4]，CUDA中也有类似规定 [5].</p> <h3 id="复合运算与条件数">复合运算与条件数</h3> <p>在获得了基本运算的相对误差估计后，一个自然的问题就是考虑一系列运算下，最终结果的误差是如何被这些基本误差bound的。例如 \(f(x) = \frac{1 - \cos x}{x^2}\) 就是以下一组基本运算的结果。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">z</span> <span class="o">=</span> <span class="nf">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">z</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">k</span> <span class="o">/</span> <span class="n">y</span>
</code></pre></div></div> <p>假设基本运算可微，有如下结果。 \(\begin{aligned} \operatorname{Err}_{r e l}(f(x), f(x+\Delta x)) &amp; =\frac{f(x+\Delta x)-f(x)}{f(x)} \\ &amp; =\frac{f(x+\Delta x)-f(x)}{\Delta x} \cdot \frac{\Delta x}{f(x)} \\ &amp; =\left(f^{\prime}(x)+\frac{f^{\prime \prime}(x+\theta \Delta x)}{2!} \Delta x\right) \cdot \frac{\Delta x}{f(x)}, \theta \in(0,1) \\ &amp; =\frac{\Delta x}{x} \cdot\frac{x f^{\prime}(x)}{f(x)}+O\left((\Delta x)^2\right) \\ &amp; =\operatorname{Err}_{r e l}(x, x+\Delta x) \cdot\frac{x f^{\prime}(x)}{f(x)}+O\left((\Delta x)^2\right) \end{aligned}\)</p> <p>我们称 \(\Gamma(x) = \frac{x f'(x)}{f(x)}\) 为<em>条件数</em>, 也就是放大误差的倍数。直觉上来看，就是自变量的相对误差被放大了条件数倍。显然，利用这一结论，我们可以给出整个运算的误差估计。</p> <h3 id="求和">求和</h3> <blockquote> <p>参考 [2] 4节 Summation</p> </blockquote> <p>给定一列数字 \(a[0], a[1], ..., a[n-1]\), 求和是极其常见的操作，对于它的误差估计也很重要。最直观的求和方法如下：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">)):</span>
    <span class="n">s</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</code></pre></div></div> <p>也就是每次都使用求和的结果和数组里的下一个元素相加，称为 <em>递归求和</em>。事实上我们也可以将这些数字两两组合然后相加，还有其他等等方法。</p> <p>无论如何相加，我们都可以用下面的算法来表示，也就是每次在所有数字（包括中间求和的结果）中选两个数字相加：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>S = {a[0], ..., a[n-1] }.
while len(S) &gt; 1
	x, y = 选择 S 中两个元素移除
	z = x + y
	S.add(z)
end
</code></pre></div></div> <p>我们的误差分析也就基于上面的一般性算法，从而会偏高。</p> <p>考虑第 \(i\) 次加法 \(T_i = x_{i_1} + y_{i_1}\), 满足： \(\hat{T_i} = \frac{x_{i_1} + y_{i_1}}{1 + \delta_i}, |\delta_i| \le u\) 这里的 \(u\) 就是加法的误差界？显然一次加法运算的局部误差为 \(\delta_i \hat{T}_i\), 全局误差就是局部误差的总和 \(E_n = S_n - \hat{S_n} = \sum_{i=1}^{n-1}\delta_i\hat{T_i}\) 可想而知，可能的最小误差界是 \(|E_n| \le u\sum_{i=1}^{n-1}|\hat{T_i}|\). 容易发现 \(|\hat{T}_i| \le \sum_{j=1}^n |x_j| + O(u)\), 所以我们可以得到误差 \(|E_n| \le (n-1) u \sum_{i=1}^n|x_i| + O(u^2)\)</p> <p>而相对误差也就小于等于 \((n-1)u\).</p> <p>这一分析实际上还给了我们一个启示：想要最小化求和的误差，就要最小化这些中间结果。然而，这一问题一般来说是 NP-hard 的。对于递归求和的情况，如果所有元素都非负的，显然最好的方法就是从最小到大加。</p> <h3 id="矩阵乘法">矩阵乘法</h3> <blockquote> <p>参考 [2] 3 节</p> </blockquote> <p>最后我们来讨论矩阵乘法的误差。在此之前，我们需要对于向量内积的分析。</p> <p>援引 [2].3.1 的结论 \(|x^T y - \widehat{x^T y} | \le \gamma_n\sum_i^n|x_iy_i| = \gamma_n|x|^T|y|, \gamma_n = \frac{nu}{1-nu}\) 如果 \(nu \le 0.01\), 可以加强到 \(1.01n u |x|^T|y|\). 这里的 \(u\) 如上，也就是 \(\delta_i\) 的最大值。</p> <p>基于此，对于矩阵乘法 \(C = A B\) 我们有 \(|C - \hat{C}| \le \gamma_n |A| |B|.\)</p> <h5 id="奇怪的东西">奇怪的东西</h5> \[\delta C =((A+\Delta A) (B + \Delta B) -AB) / AB = (A\Delta B + \Delta A B) / AB \\ = (A(B\cdot\delta B) + (A\cdot \delta A)B) / AB\] \[((1+\delta_1)x_1 + \dots + (1+\delta_n)x_n -S)/S = \sum(\delta_i x_i) / S\] <h3 id="参考文献按重要程度排序">参考文献（按重要程度排序）</h3> <p>[1] David Goldberg. 1991. What every computer scientist should know about floating-point arithmetic. ACM Comput. Surv. 23, 1 (March 1991), 5–48. https://doi.org/10.1145/103162.103163</p> <p>[2] Accuracy and Stability of Numerical Algorithms, Second Edition (2002)</p> <p>[3] https://en.wikipedia.org/wiki/Machine_epsilon</p> <p>[4] <a href="https://www.gnu.org/software/libc/manual/html_node/Errors-in-Math-Functions.html">https://www.gnu.org/software/libc/manual/html_node/Errors-in-Math-Functions.html</a></p> <p>[5] https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#standard-functions</p>]]></content><author><name>[&quot;詹奇&quot;]</name></author><category term="cs"/><summary type="html"><![CDATA[众说周知，由于内存的有限，计算机只能通过近似的方法表示一般的实数。其中最为广泛使用的方法就是浮点数。本文介绍浮点数的表示方法，重点放在对其误差的分析和理解上。本文的诞生来自于个人科研需要的总结，势必无法面面俱到。]]></summary></entry><entry><title type="html">这个幻灯片模版, 终于被我“偷”到了</title><link href="https://qi-zhan.github.io/blog/2024/markdown/" rel="alternate" type="text/html" title="这个幻灯片模版, 终于被我“偷”到了"/><published>2024-12-01T00:00:00+00:00</published><updated>2024-12-01T00:00:00+00:00</updated><id>https://qi-zhan.github.io/blog/2024/markdown</id><content type="html" xml:base="https://qi-zhan.github.io/blog/2024/markdown/"><![CDATA[<p>当年在看蒋炎岩老师操作系统课程就发现他的幻灯片模版很好看 (当然课更值得看), 是基于 Markdown 方言利用 Reveal.js 渲染的. 我一直很想复刻一个, 奈何我自己对于色彩, CSS样式的定制实在是没啥水平, 就搁置了.</p> <p>最近发现 GitHub 上已经有一个相当好的复刻了 <a href="https://github.com/zweix123/jyyslide-md">https://github.com/zweix123/jyyslide-md</a> (大喜), 于是 fork 过来根据我自己的需求又改了一下. 主要是增加了多列布局和改掉了难用的 poetry, 多了一个 watch 然后重新编译的功能, 我自己现在用的也比较舒服了. 我自己的仓库: <a href="https://github.com/Qi-Zhan/jyyslide-md">https://github.com/Qi-Zhan/jyyslide-md</a></p> <p>感兴趣的同学可以在 <a href="https://qi-zhan.github.io/jyyslide-md/#/">https://qi-zhan.github.io/jyyslide-md/#/</a> 直接预览一下, 我自我感觉平时组会和一些小场合讲讲还是挺高效的.</p>]]></content><author><name>[&quot;詹奇&quot;]</name></author><category term="cs"/><summary type="html"><![CDATA[当年在看蒋炎岩老师操作系统课程就发现他的幻灯片模版很好看 (当然课更值得看), 是基于 Markdown 方言利用 Reveal.js 渲染的. 我一直很想复刻一个, 奈何我自己对于色彩, CSS样式的定制实在是没啥水平, 就搁置了.]]></summary></entry><entry><title type="html">我的 CS 工作流</title><link href="https://qi-zhan.github.io/blog/2024/workflow/" rel="alternate" type="text/html" title="我的 CS 工作流"/><published>2024-01-20T00:00:00+00:00</published><updated>2024-01-20T00:00:00+00:00</updated><id>https://qi-zhan.github.io/blog/2024/workflow</id><content type="html" xml:base="https://qi-zhan.github.io/blog/2024/workflow/"><![CDATA[<p>本文简单介绍和总结一下我日常科研所使用的一些软件与配置.</p> <h3 id="编辑器-vscode">编辑器 VSCode</h3> <p>对于 CS 科研狗来说最重要的东西莫过于编辑器/IDE了. 据我观察, 身边同龄人几乎都用 VSCode, 我自然也不例外.</p> <h4 id="字体与主题">字体与主题</h4> <ul> <li>字体: <a href="https://github.com/tonsky/FiraCode">Fira Code</a>, 主要原因是我个人非常喜欢连体字的显示效果.</li> <li>主题: <a href="https://marketplace.visualstudio.com/items?itemName=onecrayon.theme-quietlight-vsc">Quiet Light for VSC</a>, 我个人非常喜欢的白天主题颜色, 尤其喜欢深红色的函数名.</li> </ul> <h4 id="vim-模式">Vim 模式</h4> <blockquote> <p>如何生成随机字符串？让一个 Windows 用户使用 Vim，然后让他退出。</p> </blockquote> <p>或许我的配置里面最值得拿出来说的就是这个 <a href="https://github.com/VSCodeVim/Vim">Vim 插件</a>了. <strong>(这也是我发这篇文章想要安利的主要的东西)</strong></p> <p>首先我并不是一个经典和重度的 vim 用户, 也记不住那么多快捷键, 使用的最多的功能无非是 hjkl(代替上下左右移动光标), dd(删除本行), w(下一个词), shift a(行尾插入) 和 visual 模式下对多行的同时操作.</p> <p><strong>我推荐 Vim 模式插件的主要原因是我们可以舒适的把合理的按键映射到 VSCode 本身提供的功能</strong>.</p> <p>举几个例子, vsc 里面有些我个人(大部分人)<strong>特别常用</strong>的功能:</p> <ul> <li>cmd + shift + p, 打开命令面板.</li> <li>cmd + p, 查找当前工作区的文件.</li> <li>cmd + shift + o, 查找当前文件的符号(查找函数之类的)</li> <li>切换不同的打开的文件, previous/next editor.</li> <li>把终端调高调低, 这个看终端显示的时候比较常用. 我以前使用鼠标的时候使用体验较差, 总是要拉到终端的边缘才能调整大小.</li> </ul> <p>也有与语言相关的功能(需要对应语言插件):</p> <ul> <li>查看函数的定义, 按住 cmd 点击函数名.</li> <li>查看函数的文档, 也就是鼠标悬停在函数上面的时候显示的那个文档.</li> <li>重命名变量, 右键点击变量名, 选择 rename symbol.</li> </ul> <p>这些功能特别实用, 而 VSCode 都提供了对应的命令, 有的有快捷键, 有的可以自己设置快捷键, 但我在使用中感觉并不好:</p> <ul> <li>快捷键记不住或者难按, 由于不能和已有的快捷键和普通键冲突, 所以大部分快捷键都并不自然, 尝试记住这些快捷键还不如鼠标点一下.</li> </ul> <p><strong>所以一个自然的想法就是能不能区分不同的模式, 我们平时在编辑代码的时候就是插入模式, 而需要一些特殊操作的时候进入一个normal模式, 这个模式时我们可以把普通的好记的按键映射到那些想要的功能.</strong> 而这个 idea, 几十年前的 vim 就已经实现了.</p> <p>所以我就利用 vim 的各种模式, 把上面提到的那些功能映射到了舒服切好记的按键.</p> <p>从<a href="https://github.com/Qi-Zhan/vscode-vim-config">这里</a>可以看到我对于 vscode vim 的全部配置, 同样举一些我自己用的例子:</p> <ul> <li>shift + : 打开命令面板. ff(find file) 找文件, fs(find symbol) 找符号.</li> <li>rn(rename) 重命名符号</li> <li>gd(go definition) 跳转到定义, gb(go back) 跳回来, ge(go error) 跳转到错误的地方.</li> <li>tab/shift tab 切换到 previous/next editor.</li> <li><code class="language-plaintext highlighter-rouge">&gt;</code> 把当前 editor 推到右边, 这个对于想同时对照看两个文件的时候很有用.</li> <li>control + ~ 切换终端和编辑器, cmd + j/k 调整终端大小, 这个体验也很不错.</li> <li>j+j 进入 normal mode.</li> <li>… 还有一些, 详见配置文件.</li> </ul> <blockquote> <p>本来想搞个 gif 演示一下的, 但是由于我太懒了, 就没做 :-(</p> </blockquote> <p>在 vim mode 的帮助下, 记住这些快捷键可谓是相当容易了(大概), 你可以用你自己直觉上记得住的按键, 反正都是由自己配置的, 自己体验好就行.</p> <p>当然了, 当我慢慢开始使用 vim 时, vim 本身的逻辑和功能也给我带来了一些方便, 这就与我要介绍的重点无关了, 感兴趣的同学可以自行搜索.</p> <h4 id="其他插件">其他插件</h4> <p>这里再推荐几个我觉得比较好用的插件.</p> <ul> <li>Error lens, 可以在代码中直接显示错误信息, 不用再去下方的错误提示栏中查看.</li> <li>indent-rainbow 提供彩虹色锁进.</li> <li>各种语言的插件, 这里特别推荐 clangd, 有时候比微软那套 C++/ C 好用.</li> <li>Copilot, 不用说了.</li> <li>vscode-icons 提供更好看的图标, 纯粹是看着舒服.</li> </ul> <p>最后, 我在写 Java 的时候我会是选择 IDEA, 但是最近和未来大概都没有写 Java 的打算, 也就不再赘述.</p> <h3 id="shell-与-terminal">Shell 与 Terminal</h3> <h4 id="fish">fish</h4> <p>Shell 其实在工作中用的还是比较多的, 被jyy老师在网课上安利之后我就选择了 fish. 使用它的最主要原因就是<strong>开箱即用</strong>的智能补全, 这个功能在真正写命令的时候极其好用, 从此不用再把命令复制到文件里用的时候再拷贝出来了 :-).</p> <p>除此之外, abbr, 即缩写也是一个不错的功能, 比如我在 fish 的配置文件中写了这么一段:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>➜  ~                                                              <span class="o">(</span>zju<span class="o">)</span>
   abbr <span class="nt">-a</span> <span class="nt">--</span> m make
   abbr <span class="nt">-a</span> <span class="nt">--</span> c cargo
</code></pre></div></div> <p>我在敲击 <code class="language-plaintext highlighter-rouge">m</code> 的时候就会自动补全为 <code class="language-plaintext highlighter-rouge">make</code>, 敲击 <code class="language-plaintext highlighter-rouge">c</code> 的时候就会自动补全为 <code class="language-plaintext highlighter-rouge">cargo</code>. 这样的话有时候可以让手指舒服点…</p> <blockquote> <p>fish 的一个弊端是与 bash 语法不兼容, 使用时要注意一下.</p> </blockquote> <h4 id="iterm2">Iterm2</h4> <p>MacOS 上的默认终端是 Terminal, 但是我使用 Iterm2, 也没有什么特别的原因, 就是 iterm2 可以显示的色彩更多一点?</p> <h3 id="实用命令行工具">实用命令行工具</h3> <p>随着 Rust 等现代编程语言的发展, 有很多人用这些语言重写了部分经典的命令行工具, 感兴趣的同学可见 <a href="https://github.com/ibraheemdev/modern-unix">modern unix</a>, 这里介绍几个我用的比较多的.</p> <ul> <li>du -&gt; dust. dust 可以更舒适的查看整个文件夹的占用大小分布, <a href="https://github.com/bootandy/dust/blob/master/media/snap.png">看张图你就懂了</a>.</li> <li>find -&gt; fd. 更舒适的查找文件, 比如 <code class="language-plaintext highlighter-rouge">fd -e md</code> 就是查找所有的 markdown 文件, <code class="language-plaintext highlighter-rouge">fd -e rs mod</code> 就是查找所有的 rust 模块文件.</li> <li>cat -&gt; bat. 更舒适的查看文件, 适合你要在有语法高亮的情况下简单查看某个文件的情形.</li> </ul> <h3 id="其他">其他</h3> <ul> <li>包管理器 Homebrew. MacOS 上的包管理器, 没啥好说的.</li> <li>文献阅读 Zotero. 标准的文献管理软件, 使用插件可以直接在浏览器中导入文献, 划词翻译也挺好用的.</li> <li>Markdown 编译器 Obsidian. 这方面其实我没有什么要求, 就是一个写笔记做总结的 markdown 集中放置的地方, 所以也没有进行过多的配置. 使用 Obsidian 纯粹是 Typora 不免费了.</li> </ul>]]></content><author><name>[&quot;詹奇&quot;]</name></author><category term="cs"/><summary type="html"><![CDATA[本文简单介绍和总结一下我日常科研所使用的一些软件与配置.]]></summary></entry><entry><title type="html">符号执行, KLEE 与 LLVM</title><link href="https://qi-zhan.github.io/blog/2023/klee_learning/" rel="alternate" type="text/html" title="符号执行, KLEE 与 LLVM"/><published>2023-12-16T00:00:00+00:00</published><updated>2023-12-16T00:00:00+00:00</updated><id>https://qi-zhan.github.io/blog/2023/klee_learning</id><content type="html" xml:base="https://qi-zhan.github.io/blog/2023/klee_learning/"><![CDATA[<p>最近在尝试使用 KLEE 科研，这里记录一些学习笔记。</p> <h2 id="符号执行一瞥">符号执行一瞥</h2> <p>众所周知，一般的测试都是基于具体的输入，观察程序的行为。 而符号执行的基本思想是，将程序的输入符号化，然后通过符号执行引擎运行程序，得到程序的执行路径，然后通过约束求解器求解路径上的约束，得到具体的输入。具体的知识和例子可参考 [1]，不再赘述。一篇我认为总结的很好的综述。由于我们的目的是进一步的了解符号执行和 KLEE, 所以我们也会偏重总结 KLEE 对于符号执行里的经典问题的选择。</p> <h3 id="执行引擎">执行引擎</h3> <p>符号执行的核心是对于一段具体的代码，究竟该如何执行它，也就是执行引擎。我在看 KLEE 的时候，发现它认为自己是 dynamic symbolic execution(DSE), 但奇怪的是，很多文献将 DSE 和 concolic execution(CE) 混在一起谈论， 但在我的理解下 KLEE 的实现还是比较接近传统符号执行的，CE 在我的认知下是 DART[4] 采用的方法，每次都用具体输入运行然后解约束生成下一个具体的输入的方法，很明显和 KLEE 的做法不一致。 那难道 KLEE 不是 DSE？然而其官网上第一句话就是 KLEE is a dynamic symbolic execution engine built on top of the LLVM compiler infrastructure.</p> <p>这个问题我想了很久，最终在 [2] [3] 这两个资料下得到了解答，符号执行这个词在发展过程中经过了太多的使用。已经需要进一步分类才能区分主流方法了。下面是我根据各种资料再次总结的符号执行的分类：</p> <h4 id="动态符号执行dse">动态符号执行(DSE)</h4> <p>动态符号执行混合了具体的程序执行和符号的程序执行，以此来提升运行效率和解决与环境交互的问题。而 DSE 又能再次进行分类：</p> <ol> <li> <p>“Offline” DSE, 也就是著名的 concolic execution(CE). 它们依赖具体的程序执行来驱动符号的执行。即，<strong>CE 每次的执行都是具体的值的运行</strong>，同时维持一个符号化的约束列表(通过插桩等方法记录约束和具体值的走向)，在真正执行完后，尝试翻转约束列表里面的一些约束得到新的约束然后解得新的具体的程序输入。这也解释了为什么称为离线，因为是在每次具体执行结束之后才求解得到新输入。[5] 的实验内容很好的解释了该如何实现以及有什么好处，推荐感兴趣的同学完成。CE 本质上更像是测试，所以和环境交互并没有太大困难，只是会丢失一些符号状态和相应约束。除了 DART，还有 SAGE, PEX (Microsoft), CUTE (UIUC), CREST (Berkeley) 等工具。</p> </li> <li> <p>“Online” DSE, 也就是 EXE(KLEE), 还有 SPF (NASA Java), Cloud9 这些工具采用的方法，也是我们主要关心的。程序的初始值是符号值的输入，运行程序时如果目标都是具体值就正常执行，如果有一个符号值就采用 expr tree 符号化执行。在遇到分支指令时，fork 出新的状态然后在两边添加对应的约束。在执行终止时求解约束得到具体的测试输入。</p> </li> <li> <p>Selective Symbolic Execution. 交替进行具体执行和符号执行，可以聚焦于感兴趣的代码符号执行，例如 S\(^2\)E.</p> </li> </ol> <p>这也就解决了我的主要疑问，DART 和 KLEE 代表的是 DSE 下的两类方法，由此我认为将 DSE 和 CE 视为同一个东西是不太合理的，只要具体的运行代码了，无论是具体化还是符号化都应当视作 DSE.</p> <h4 id="静态符号执行sse">静态符号执行(SSE)</h4> <p>既然有 DSE, 那肯定就有 SSE，这也是一开始我很疑惑的地方。都是符号环境下运行，普通的 SSE 和以 KLEE 为代表 DSE 区别在哪里？从 [6] 中讲的内容，我个人理解 SSE 更好的理解方式是当成正向的验证策略。基于 hoare 逻辑的验证求的是最弱前条件，然后利用求解器检验当前的前条件能否推出最弱前条件。那么如果我们换一个思路，从前往后来尝试验证，那就可以通过程序的语义来(具体见 [6])抽象代码收集约束并最终完成<strong>前向</strong>的验证。 SSE 的考量中没有路径爆炸的问题(?)，因为它总是像经典的静态分析一样合并路径，通过一个符号表达式来抽象所有的路径。</p> <p>[7] 中也有一个不错的总结：SSE 是 statement-based. DSE 是 path-based. DSE 每次在 <strong>一条路径</strong> 上探索程序，为每条路径生成约束。 而 SSE 遍历程序，将整个语句转换成公式，这里的公式则代表了任一路径的性质。可以将漏洞描述成</p> <h4 id="纯符号执行pure-se">纯符号执行(Pure SE)</h4> <p>纯符号执行枚举程序的路径收集约束然后检测这些条件能否满足。这好像是在分离逻辑验证用的比较多，我就不太懂了 :).</p> <h4 id="分类总结">分类总结</h4> <p>综上所述，<strong>我最终的理解是</strong>，总是运行具体的输入且通过收集路径约束得到下一个具体输入的就是 CE, 这是 DSE 的一种形式，另一种 DSE 则是在符号化基础上解释程序，遇到分支则 fork 出新状态，最后通过约束求解器求解约束得到具体的输入。而 DSE 与 SSE 的最大区别在于 DSE 上按照测试的路子一条路径一个状态(path based)。而 SSE 的视角不同，是按照静态分析的路子尝试抽象(statement-based)，力图只分析一条合并的路径(?)。<strong>感觉平时我们讨论的最广泛的符号执行其实都是指动态符号执行。</strong></p> <blockquote> <p>虽说费劲心思查了好久资料想这个问题在实践上并没有什么用，而且实践上很多方法就是把各种符号执行技术混起来用的，但尝试搞清楚总是有些裨益 :(</p> </blockquote> <h3 id="内存模型">内存模型</h3> <p>内存模型同样符号执行中重要且不易处理的问题。 符号执行过程中，除了遇到那些显然的指令(算法运算)，对于指针和数组取址的处理就涉及到了一个大难题：如何建模内存。这听起来是个很简单的事情，直觉上来看把它当做一个大数组就行了，然而当指针和下标是符号值的情况下，这个问题就变得复杂了。</p> <p>对于数组的下标，一种简单的方法是假设这个符号值可以是有界集合中的任意一个下标，也就是每个情况 fork 一个新状态。而如 KLEE 一般会利用 SMT 里面的 array 相关 theory, 直接将数组作为约束的一等公民(first class)，将数组和相关操作编码进了约束求解器里面。</p> <p>而对于符号化地址的处理则更加麻烦。原则上来说一个符号化的地址可以指向内存的任何一个地方，但如果真要这么考虑状态实在是太多了。所以实践中有些方法采用 address concretization, 地址具体化的方法。而 KLEE 则是将每一个内存的对象都映射到一个数组上，这样就将一个平坦的地址空间映射到了一个分段的地址空间上。</p> <p>具体的处理我们在后面讨论 KLEE 源码中内存相关操作时再详细介绍。</p> <h3 id="与环境交互">与环境交互</h3> <p>环境的交互(系统环境与应用环境)同样也是符号执行遇到的难题。简单来说就是遇到难以符号执行的代码时该怎么处理，例如打开一个文件的返回值，调用没有源码的库函数/底层函数等等。 早期的一些工作 DART, EXE 等选择不处理，也就是放弃对这些函数的符号执行，采用具体的输入来让程序继续运行下去。</p> <p>而 KLEE 则是自己实现了一套基本的符号文件系统来抽象与文件系统交互的过程。</p> <h3 id="缓解路径爆炸">缓解路径爆炸</h3> <p>当程序中有循环时，符号执行会产生大量的路径(每个 while 语句理论上都可以有无穷路径). 所有实践中使用的符号执行工具都会遇到路径爆炸的问题，而多数工具都有自己的或启发式，或经验的方法来缓解。</p> <p>一些很自然的方法包括：</p> <ul> <li>eager evaluation 经常性的检查约束能否满足而不是到最后再次求解一个庞大的约束，对无解的状态直接剪枝。</li> <li>summary 对函数和循环做摘要，生成一个直接的映射关系就不用重复计算了。这个技巧在经典的静态分析中也很常见。</li> <li>Interpolation 没咋看懂</li> <li>state merge 状态合并。</li> </ul> <p>例如在对于下面这段代码：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">foo</span><span class="p">(</span><span class="kt">int</span> <span class="n">x</span><span class="p">,</span> <span class="kt">int</span> <span class="n">y</span><span class="p">)</span> <span class="p">{</span> 
  <span class="k">if</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">)</span> 
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="mi">2</span><span class="p">;</span> 
  <span class="k">else</span> 
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="mi">3</span><span class="p">;</span> 
  <span class="k">return</span> <span class="n">y</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>按照一般的情况会生成两个状态 \(\pi = \alpha_x &lt; 5, y = 2 * \alpha_x\); \(\pi = \alpha_x \ge 5, y = 3 * \alpha_x\), 利用 SMT 的表示能力 ite(if-then-else) 我们可以将这两个状态合并成一个状态 \(\pi = \text{true}, y = \text{ite}(\alpha_x &lt; 5, 2 * \alpha_x, 3 * \alpha_x)\).</p> <p>对于类似的情况状态合并总是可以做的，但这也显示是一个 trade-off, 因为这加剧了求解器的负担。这也就诞生了很多启发式的方法，比较有名的是 Veritesting, 它根据简单和困难的语句来考虑是否合并，那些系统调用，也是经典的 DSE 和 SSE 混合使用的例子。</p> <h3 id="约束求解">约束求解</h3> <p>约束的求解并不是我目前太关心的问题，简单总结一下我在 [1] 中看到的一些 KLEE 使用的一些优化策略。</p> <ul> <li>重写/简化表达式</li> <li>implied value concretization, 对于可以推断得到的符号值，直接替换为具体值</li> <li>KLEE 还有一个比较有趣的，称为 counterexample caching 的方法。通过一个 cache, 约束集合映射到一组具体的赋值。当不可满足集合(SMT 无解)在 cache 里面且是我们要求的 S 的子集时，显然 S 也不可满足。同样如果可满足集合是 S 的超集，那 S 也可满足，即使是 S 的子集，也可以优先代入试试看。</li> </ul> <h2 id="klee">KLEE</h2> <p>OK，我们现在进入 KLEE 源码分析阶段。希望能在解释清楚 KLEE 大致流程的同时，<strong>能和前面的理论级别的阐释</strong>对应。 安装过程采用了 KLEE 提供的 Docker 镜像，十分方便，不再赘述。</p> <h3 id="主循环">主循环</h3> <p>KLEE 的主循环出奇的简单且符合预期：</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// lib::Core::Executor </span>
<span class="c1">// void Executor::run(ExecutionState &amp;initialState)</span>
<span class="k">while</span> <span class="p">(</span><span class="o">!</span><span class="n">states</span><span class="p">.</span><span class="n">empty</span><span class="p">()</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">haltExecution</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 由当前使用的 searcher 选择下一个要 run 的状态</span>
    <span class="n">ExecutionState</span> <span class="o">&amp;</span><span class="n">state</span> <span class="o">=</span> <span class="n">searcher</span><span class="o">-&gt;</span><span class="n">selectState</span><span class="p">();</span>
    <span class="c1">// 当前状态的指令</span>
    <span class="n">KInstruction</span> <span class="o">*</span><span class="n">ki</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">pc</span><span class="p">;</span>
    <span class="c1">// 指令往前偏移</span>
    <span class="n">stepInstruction</span><span class="p">(</span><span class="n">state</span><span class="p">);</span>
    <span class="c1">// 执行指令</span>
    <span class="n">executeInstruction</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">ki</span><span class="p">);</span>
    <span class="c1">// 更新状态集合，例如增加新产生的状态，删除已经结束的状态</span>
    <span class="n">updateStates</span><span class="p">(</span><span class="o">&amp;</span><span class="n">state</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p>当然这里面最重要的就是 <code class="language-plaintext highlighter-rouge">executeInstruction</code> 了，真正的解释执行每一个 LLVM IR, 约 <strong>1.3k</strong> LOC, 我简化了大部分代码：</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="n">Executor</span><span class="o">::</span><span class="n">executeInstruction</span><span class="p">(</span><span class="n">ExecutionState</span> <span class="o">&amp;</span><span class="n">state</span><span class="p">,</span> <span class="n">KInstruction</span> <span class="o">*</span><span class="n">ki</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">Instruction</span> <span class="o">*</span><span class="n">i</span> <span class="o">=</span> <span class="n">ki</span><span class="o">-&gt;</span><span class="n">inst</span><span class="p">;</span>
  <span class="k">switch</span> <span class="p">(</span><span class="n">i</span><span class="o">-&gt;</span><span class="n">getOpcode</span><span class="p">())</span> <span class="p">{</span>
    <span class="c1">// 算数表达式，最典型且最易处理的情况</span>
    <span class="k">case</span> <span class="n">Instruction</span><span class="o">::</span><span class="n">Add</span><span class="p">:</span> <span class="p">{</span>
      <span class="n">ref</span><span class="o">&lt;</span><span class="n">Expr</span><span class="o">&gt;</span> <span class="n">left</span> <span class="o">=</span> <span class="n">eval</span><span class="p">(</span><span class="n">ki</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">state</span><span class="p">).</span><span class="n">value</span><span class="p">;</span>
      <span class="n">ref</span><span class="o">&lt;</span><span class="n">Expr</span><span class="o">&gt;</span> <span class="n">right</span> <span class="o">=</span> <span class="n">eval</span><span class="p">(</span><span class="n">ki</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">state</span><span class="p">).</span><span class="n">value</span><span class="p">;</span>
      <span class="c1">// 找到 ki 对应的 target index, 赋一个 AddExpr</span>
      <span class="n">bindLocal</span><span class="p">(</span><span class="n">ki</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">AddExpr</span><span class="o">::</span><span class="n">create</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">));</span>
    <span class="p">}</span>
    <span class="c1">// cast 转类型指令略过</span>
    <span class="c1">// 控制流指令, 最经典的 fork 处理，一边增加 condition 为 true 的约束，一边增加 condition 为 false 的约束</span>
    <span class="k">case</span> <span class="n">Instruction</span><span class="o">::</span><span class="n">Br</span><span class="p">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">}</span>
    <span class="c1">// ** 内存相关指令 **</span>
    <span class="k">case</span> <span class="n">Instruction</span><span class="o">::</span><span class="n">Alloca</span><span class="p">:</span> <span class="p">{</span>
      <span class="c1">// 一些与 LLVM 的交互得到要分配的内存大小</span>
      <span class="n">executeAlloc</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="nb">true</span><span class="p">,</span> <span class="n">ki</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="c1">// 这个 executeMemoryOperation 后面重点讨论</span>
    <span class="k">case</span> <span class="n">Instruction</span><span class="o">::</span><span class="n">Load</span><span class="p">:</span>
    <span class="k">case</span> <span class="n">Instruction</span><span class="o">::</span><span class="n">Store</span><span class="p">:</span> <span class="p">{</span>
      <span class="n">executeMemoryOperation</span><span class="p">(...);</span>
    <span class="p">}</span>
    <span class="c1">// GEP 只计算地址，不参与内存运行，怪不得看起来比较 trivial</span>
    <span class="c1">// &lt;https://llvm.org/docs/LangRef.html#getelementptr-instruction&gt;</span>
    <span class="k">case</span> <span class="n">Instruction</span><span class="o">::</span><span class="n">GetElementPtr</span><span class="p">:</span> <span class="p">{</span>
      <span class="p">...</span>
    <span class="p">}</span>
  <span class="p">}</span>    
<span class="p">}</span>
</code></pre></div></div> <p>eval 函数如我们前面所介绍的，常量就从常量池里面取，变量就从当前栈帧的局部变量里面取。其中的 <code class="language-plaintext highlighter-rouge">index</code> 建立与我想在后面介绍的构建系统相关。</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="n">Cell</span><span class="o">&amp;</span> <span class="n">Executor</span><span class="o">::</span><span class="n">eval</span><span class="p">(</span><span class="n">KInstruction</span> <span class="o">*</span><span class="n">ki</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">index</span><span class="p">,</span> 
                           <span class="n">ExecutionState</span> <span class="o">&amp;</span><span class="n">state</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">vnumber</span> <span class="o">=</span> <span class="n">ki</span><span class="o">-&gt;</span><span class="n">operands</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">vnumber</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// 常量</span>
    <span class="kt">unsigned</span> <span class="n">index</span> <span class="o">=</span> <span class="o">-</span><span class="n">vnumber</span> <span class="o">-</span> <span class="mi">2</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">kmodule</span><span class="o">-&gt;</span><span class="n">constantTable</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span> <span class="c1">// 变量</span>
    <span class="kt">unsigned</span> <span class="n">index</span> <span class="o">=</span> <span class="n">vnumber</span><span class="p">;</span>
    <span class="n">StackFrame</span> <span class="o">&amp;</span><span class="n">sf</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">stack</span><span class="p">.</span><span class="n">back</span><span class="p">();</span>
    <span class="k">return</span> <span class="n">sf</span><span class="p">.</span><span class="n">locals</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <h3 id="状态管理">状态管理</h3> <p>KLEE 中的状态，也就是一个个被 fork 出的分支路径，在 <code class="language-plaintext highlighter-rouge">/klee/Execution-State.h</code> 中, 主要包含两类 objects:</p> <ul> <li>AddressSpace: 包含了当前状态所有 objects 的元数据，包括全局，局部和堆上的对象。<code class="language-plaintext highlighter-rouge">AddressSpace::resolveOne</code> 用于解析一个地址，返回一个 <code class="language-plaintext highlighter-rouge">ObjectState</code> 对象。</li> <li>ConstraintManager: 记录约束。</li> </ul> <h3 id="内存相关操作">内存相关操作</h3> <p>简单的符号执行在上文讨论的函数 <code class="language-plaintext highlighter-rouge">executeInstruction</code> 中已经是自明的了。但是对于内存相关的操作，例如 <code class="language-plaintext highlighter-rouge">Load</code> 和 <code class="language-plaintext highlighter-rouge">Store</code> 就需要进一步的处理了。这里也能对应前文对于 KLEE 内存模型的讨论，也是我接下来工作比较关心的部分。下面的内容大量参考 [8], 一篇介绍 KLEE 内部实现的文章。</p> <h4 id="executememoryoperation">executeMemoryOperation</h4> <p>KLEE 中两个与内存相关的类是 <code class="language-plaintext highlighter-rouge">MemoryObject</code> 和 <code class="language-plaintext highlighter-rouge">ObjectState</code>, 定义在 <code class="language-plaintext highlighter-rouge">lib/Core/Memory.h</code> 中。</p> <p>MemoryObject 用来表示一个有基址和大小的 object, 在 <code class="language-plaintext highlighter-rouge">executeMemoryOperation</code> 中 KLEE 自动确保这样的访问是合法的，MemoryObject 提供了一些方便的方法来实现这一点。如果说 MemoryObject 关注的是 Object 的空间一致性，那么 ObjectState class 的作用就是用来真正访问状态里的内存值。</p> <p>如我们上面看到的， Load 和 Store 指令的实现都来自<code class="language-plaintext highlighter-rouge">executeMemoryOperation</code>. 这个函数的实现混合了 我们前面提到的 AddressSpace, MemoryObject::getBoundsCheckOffset, ObjectState, 如果出现了 overflow 就会报错并终止当前状态。</p> <h3 id="构建过程">构建过程</h3> <p>KLEE 是基于 LLVM IR 的，所以这里的构建过程指的是 KLEE 是如何通过 wrapper 的方式将一个项目的字节码(.bc 文件) 转换成适合自身处理的代码。例如前面的 <code class="language-plaintext highlighter-rouge">eval</code> 函数里面的表的建立，各种 IR 相关信息的获取。这个部分在符号执行的技术上是不太重要的，主要是工程实践相关，但如果我们也想做类似的基于某一种 IR 的进一步操纵，看看如何包装还是有一定参考价值的。</p> <p>经过我一番寻找，这里面最重要的函数应该是 <code class="language-plaintext highlighter-rouge">lib:module:KModule::manifest</code>:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="n">KModule</span><span class="o">::</span><span class="n">manifest</span><span class="p">(</span><span class="n">InterpreterHandler</span> <span class="o">*</span><span class="n">ih</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">forceSourceOutput</span><span class="p">)</span> <span class="p">{</span>
  <span class="cm">/* Build shadow structures */</span>
  <span class="cm">/* 把所有指令搞个表，trivial */</span>
  <span class="n">infos</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">InstructionInfoTable</span><span class="o">&gt;</span><span class="p">(</span>
      <span class="k">new</span> <span class="n">InstructionInfoTable</span><span class="p">(</span><span class="o">*</span><span class="k">module</span><span class="p">.</span><span class="n">get</span><span class="p">()));</span>

  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Function</span> <span class="o">*&gt;</span> <span class="n">declarations</span><span class="p">;</span>

  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="n">Function</span> <span class="o">:</span> <span class="o">*</span><span class="k">module</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// wrapper KFunction, 里面有 wrapper KInstruction</span>
    <span class="c1">//</span>
    <span class="c1">// 这里面完成了我感兴趣的 local 的绑定和计算</span>
    <span class="k">auto</span> <span class="n">kf</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">KFunction</span><span class="o">&gt;</span><span class="p">(</span><span class="k">new</span> <span class="n">KFunction</span><span class="p">(</span><span class="o">&amp;</span><span class="n">Function</span><span class="p">,</span> <span class="k">this</span><span class="p">));</span>
    <span class="n">functionMap</span><span class="p">.</span><span class="n">insert</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">make_pair</span><span class="p">(</span><span class="o">&amp;</span><span class="n">Function</span><span class="p">,</span> <span class="n">kf</span><span class="p">.</span><span class="n">get</span><span class="p">()));</span>
    <span class="n">functions</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">kf</span><span class="p">));</span>
  <span class="p">}</span>
  <span class="cm">/* Compute various interesting properties */</span>
  <span class="p">...</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="llvm">LLVM</h2> <p>可以看出，KLEE 的本质是在符号基础上解释 LLVM IR。我感觉多了解一些 LLVM 的使用对于现在和今后科研都能有所帮助。简单的 LLVM 介绍也不再赘述，只列出我感兴趣的(大概)更深入的内容。</p> <h3 id="一切皆-value">一切皆 Value</h3> <p>这是一开始让我感到有些奇怪的点，LLVM 的 Value Class 的描述:</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>This is a very important LLVM class. It is the base class of all values computed by a program that may be used as operands to other values. Value is the super class of other important classes such as Instruction and Function. All Values have a Type. Type is not a subclass of Value. Some values can have a name and they belong to some Module. Setting the name on the Value automatically updates the module's symbol table.

Every value has a "use list" that keeps track of which other Values are using this Value. A Value can also have an arbitrary number of ValueHandle objects that watch it and listen to RAUW and Destroy events. See llvm/IR/ValueHandle.h for details.
</code></pre></div></div> <p>原来这个 use list 是会追踪全部 value 的，而 无论是指令，或者函数都是 Value.</p> <p>To be continued…</p> <h2 id="杂项">杂项</h2> <ul> <li><a href="https://github.com/travitch/whole-program-llvm">wllvm</a> 和 <a href="https://github.com/SRI-CSL/gllvm">gllvm</a> 可以基于项目的 makefile 生成整个项目的 LLVM IR，这样可以方便的使用 KLEE 进行符号执行。</li> <li>记得加参数 <a href="https://github.com/klee/klee/issues/937">–disable-verify</a>, 否则无法加载 bitcode 文件。</li> <li>–optimize 说不定是一个很重要的参数。</li> </ul> <h2 id="参考资料">参考资料</h2> <p>[1] <a href="https://arxiv.org/pdf/1610.00502.pdf">A Survey of Symbolic Execution Techniques.</a></p> <p>[2] <a href="https://ece.uwaterloo.ca/~agurfink/stqam.w19/assets/pdf/W05-DSE.pdf">https://ece.uwaterloo.ca/~agurfink/stqam.w19/assets/pdf/W05-DSE.pdf</a></p> <p>[3] <a href="https://alastairreid.github.io/RelatedWork/notes/symbolic-execution/">https://alastairreid.github.io/RelatedWork/notes/symbolic-execution/</a></p> <p>[4] <a href="https://dl.acm.org/doi/10.1145/1065010.1065036">DART</a></p> <p>[5] <a href="https://css.csail.mit.edu/6.858/2023/labs/lab3.html">MIT lab</a></p> <p>[6] <a href="https://cmu-program-analysis.github.io/2023/index.html">CMU program analysis ch 13</a></p> <p>[7] <a href="https://softsec.kaist.ac.kr/~sangkilc/papers/avgerinos-icse14.pdf">Enhancing Symbolic Execution with Veritesting</a></p> <p>[8] <a href="https://github.com/angea/pocorgtfo/blob/master/contents/articles/18-08.pdf">KLEE Internal</a></p>]]></content><author><name>[&quot;詹奇&quot;]</name></author><category term="cs"/><summary type="html"><![CDATA[最近在尝试使用 KLEE 科研，这里记录一些学习笔记。]]></summary></entry><entry><title type="html">Python 第三方依赖引发的惨案</title><link href="https://qi-zhan.github.io/blog/2023/dependency/" rel="alternate" type="text/html" title="Python 第三方依赖引发的惨案"/><published>2023-11-24T00:00:00+00:00</published><updated>2023-11-24T00:00:00+00:00</updated><id>https://qi-zhan.github.io/blog/2023/dependency</id><content type="html" xml:base="https://qi-zhan.github.io/blog/2023/dependency/"><![CDATA[<p>最近要再复现一下论文的实验结果作为最后的检查，由于服务器重装导致原本配置的conda环境丢失，所以我需要重新配置。 本来想着在前几个月写代码的时候已经做好了<code class="language-plaintext highlighter-rouge">requirements.txt</code>，直接安装就好了，然而并没有这么顺利，在多处排查(数据集，代码，环境)之后才发现真正的原因来自第三方依赖。</p> <p>其中我的程序最核心的依赖是 <code class="language-plaintext highlighter-rouge">angr</code>，版本为 9.2.36，<code class="language-plaintext highlighter-rouge">requirements.txt</code> 如下：</p> <pre><code class="language-txt">angr==9.2.36
</code></pre> <p>安装之后当然 <code class="language-plaintext highlighter-rouge">angr</code> 的版本是符合预期的，但实验结果却很奇怪，简单来说就是得到的中间表示和预期不符，少了一些信息。我一开始还以为是不是数据集在这个诡异的服务器重装时出现了问题或者是我错误的更改了代码。而在和我另一台电脑的环境比对之后，最终发现是 <code class="language-plaintext highlighter-rouge">angr</code> 的依赖 <code class="language-plaintext highlighter-rouge">capstone</code> 的版本不一致导致的，从 5.0.1 换成 4.0.2 之后就一切正常了。</p> <p>那么为什么会出现这一问题呢，我查看了对应版本下 <code class="language-plaintext highlighter-rouge">angr</code> 的依赖，发现了这么一段：</p> <pre><code class="language-txt">capstone!=5.0.0rc2,&gt;=3.0.5rc2
</code></pre> <p>原来 <code class="language-plaintext highlighter-rouge">angr</code> 只要求不是 5.0.0rc2 且大于 3.0.5rc2 的版本，有可能开发者已经发现了 5.0 版本的 <code class="language-plaintext highlighter-rouge">capstone</code> 并不兼容所以特地排除。在我当初做实验的时候，在这个约束下会使用 4.0.2 的 <code class="language-plaintext highlighter-rouge">capstone</code>。然而到现在，<code class="language-plaintext highlighter-rouge">capstone</code> 已经有更新的 5.0.1 了，因此我们就会装目前最新的版本，但是 9.2.36 的 <code class="language-plaintext highlighter-rouge">angr</code> 并不兼容 5.0.1，最终导致实验不符合预期。而为了避免这一问题，我们只需要在 <code class="language-plaintext highlighter-rouge">requirements.txt</code> 中指定 <code class="language-plaintext highlighter-rouge">capstone</code> 的版本即可。</p> <p>没想到即使写了 <code class="language-plaintext highlighter-rouge">requirements.txt</code> 锁住了我直接依赖的库的版本，还是因为依赖的依赖的版本踩了一个大坑 :(</p> <p>本来我对于依赖这一问题是不太在意的，现在看来依赖冲突检测还是相当有意义的，即使我这种小型代码随着时间的推移也有可能出现这种难以发现的依赖问题，更不用说大型项目了。不过从技术角度来说，想要自动化的检测这种依赖冲突是相当困难的，运行时并不会有直接的异常产生。 怪不得我前几周看到的论文都是从论坛和各种地方爬取讨论的信息构建依赖冲突的知识图谱然后再进行检测的，想要检测出我面对的这种问题，使用一些简单的基于源码的依赖分析确实相当困难。</p>]]></content><author><name>[&quot;詹奇&quot;]</name></author><category term="cs"/><summary type="html"><![CDATA[最近要再复现一下论文的实验结果作为最后的检查，由于服务器重装导致原本配置的conda环境丢失，所以我需要重新配置。 本来想着在前几个月写代码的时候已经做好了requirements.txt，直接安装就好了，然而并没有这么顺利，在多处排查(数据集，代码，环境)之后才发现真正的原因来自第三方依赖。]]></summary></entry><entry><title type="html">随机游走</title><link href="https://qi-zhan.github.io/blog/2023/randomwalk/" rel="alternate" type="text/html" title="随机游走"/><published>2023-10-22T00:00:00+00:00</published><updated>2023-10-22T00:00:00+00:00</updated><id>https://qi-zhan.github.io/blog/2023/randomwalk</id><content type="html" xml:base="https://qi-zhan.github.io/blog/2023/randomwalk/"><![CDATA[<blockquote> <p>A drunk man will find his way home, but a drunk bird may get lost forever.</p> </blockquote> <p>本文使用几乎纯组合的方法证明低维随机游走的几个有趣的结论，即一维与二维随机游走的回返性与三维游走的非回返性。</p> <h2 id="一维随机游走">一维随机游走</h2> <p>一维随机游走的定义非常简单：一个动点在每一个时刻 \(n = 1, 2, \dots, 3\) 以概率 \(p\) 向上移动一格，以概率 \(q = 1 - p\) 向下移动一格。当 \(p = q=\frac{1}{2}\) 时，这个游走称为对称的。下面的讨论，我们对只考虑对称的情形。</p> <p>下图为随机游走中的一个时间-空间坐标系，横坐标代表时间，纵坐标代表位置，这样的一条折现就称为运动的<strong>轨迹</strong>。</p> <p align="center"> <img src="/assets/img/randomwalk.png" width="60%"/> </p> <h3 id="组合法基础">组合法基础</h3> <p>我们以 \(L(x, y)\) 表示从原点开始到 \((x,y)\)的轨迹的条数。当 \(x, y\) 奇偶性相同且 \(y\le x\) 时，我们有</p> \[L(x, y) = C_x^{(x+y)/2}\] <p>其他情形下，\(L(x,y) = 0\). (证明是显然的，即组合数定义)</p> <p>下面介绍本文最重要的引理——反射原理。</p> <p><strong>反射原理</strong> 假设 \(A(x_0, y_0), B(x, y), A'(x_0, -y_0)\) 是在坐标上的点，且 \(0&lt;x_0&lt;x, y_0&gt;0, y&gt;0\)，那么由 \(A\) 到 \(B\) 的<strong>与横坐标相交</strong>的路线的条数等于由 \(A'\) 到 \(B\) 的所有条数。</p> <p>证明：下图的一一映射道尽一切。</p> <p align="center"> <img src="/assets/img/reflect.png" withd="20%"/> </p> <p>在以后的叙述中，我们称路线为正的，如果它的顶点都严格位于横坐标轴上方(除了起始点)；称路线为非负的，如果它没有位于横坐标轴下方的顶点。</p> <p>由反射原理我们可以得到如下推论：</p> <p><strong>引理1</strong> 以原点 \((0,0)\) 为起点，以横坐标 \(x\) 为终点的正路线的总数：1) 当 \(x\) 为偶数时，为 \(C_{x-1}^{x/2}\)；2) 当 \(x\) 为奇数时，为 \(C_{x-1}^{(x-1)/2}\).</p> <p>证明：首先这样的路线必通过 \((1,1)\)，由 \((1,1)\) 到达横坐标 \(x\) 的路线总数为 \(\sum_{y=y_0}^xL(x-1, y-1)\), 由 \((1, -1)\) 到达横坐标 \(x\) 的路线总数为 \(\sum_{y=y_0}^{x-2}L(x-1, y+1)\), 其中</p> \[y_0 = \begin{cases} 1, &amp; x \text{为奇数} \\ 2, &amp; x \text{为偶数} \end{cases}\] <p>注意求和时 \(y\) 的取值范围，如果是 \((1,-1)\) 开始上界只能到 \(x-2\)。</p> <p>由反射原理我们知道正路线即为他们的差，也就是</p> \[\sum_{y=y_0}^xL(x-1, y-1) -\sum_{y=y_0}^xL(x-1, y+1) = L(x-1, y_0-1) = \begin{cases} C_{x-1}^{(x-1)/2}, &amp; x \text{为奇数} \\ C_{x-1}^{x/2}, &amp; x \text{为偶数} \end{cases}\] <p>一个显然的推论是，以原点 \((0,0)\) 为起点，以横坐标 \(x\) 为终点的正路线和负路线的总数为两倍的正路线，为 \(2C_{2n-1}^n=C_{2n}^n\)，若 \(x=2n\)；为 \(2C_{2n}^n\)，若 \(x=2n+1\).</p> <h3 id="一维随机游走的回返性">一维随机游走的回返性</h3> <p>有了最重要的反射原理及其推论，我们就可以证明一维随机游走的回返性了，即动点在运动后终能回到原点的概率为 \(1\).</p> <p>在考虑这一问题的时候，我们只考虑偶数步回到零的可能，即 \((0,0)\) 到 \((2n, 0)\) 的路线数。 我们以 \(u_{2n}\) 表示动点在第 \(2n\) 步时回到原点的概率，由路线数与总路线数之比可立即推得：</p> \[u_{2n} = \frac{C_{2n}^n}{2^{2n}}\] <p>其次，以 \(f_{2n}\) 表示动点在 \(2n\) 时 <strong>第一次</strong> 回到原点的概率，我们有如下引理：</p> <p><strong>引理2</strong> \(f_{2n} = u_{2n-2} - u_{2n}\) 即第一次回到原点的概率等于在第 \(2n\) 步回到原点的概率减去在第 \(2n-2\) 步回到原点的概率。</p> <p>证明：我们引入 \(A_{2n}\)：在 \(2n\) 步之内，动点一次也未返回原点，也就是正路线和负路线；\(B\) 质点于第 \(2n\) 步返回原点。由上一节的推论我们立刻知道</p> \[P(A_{2n}) = u_{2n}\] <p>我们知道 \(A_{2n-2}\bigcap B\) 表示在第 \(2n\) 步<strong>首次</strong>返回原点，因此 \(P(A_{2n-2}\bigcap B) = f_{2n}\).</p> <p>易知 \((A_{2n-1}\bigcap B)\bigcup(A_{2n-2}\bigcap \bar{B}) = A_{2n-2}\)，而从定义我们可以看到 \(2n\) 步不返回原点的事件数就是 \(2n-2\) 步不返回原点的事件交上 \(2n\) 步不返回原点的事件，也就是 \(A_{2n-2}\bigcap\bar{B}=A_{2n}\)，因此</p> \[\begin{array} P(A_{2n-2}\bigcap B) + P(A_{2n}) &amp;= P(A_{2n-2}) \\ f_{2n} + u_{2n} &amp;= u_{2n-2} \\ f_{2n} &amp;= u_{2n-2} - u_{2n} \end{array}\] <p>有了这一引理，我们立刻可以知道动点在 \(2n\) 步之内返回原点的概率为 \(f_2 + f_4+\dots+f_{2n} = 1 - u_2 - u_4 - \dots - u_{2n} = 1 - u_{2n}\).</p> <p>而斯特林公式告诉我们对于 \(u_{2n}\) 的估计：</p> \[\begin{array} nn! &amp;\approx \sqrt{2\pi n}(\frac{n}{e})^n \\ C_{2n}^n &amp;\approx 2^{2n}\sqrt{\frac{2}{\pi n}} \\ u_{2n} &amp;\approx \frac{1}{\sqrt{\pi n}} \end{array}\] <p>也就有如下定理：</p> <p><strong>定理1</strong> 一维随机游走的回返性：动点以概率 \(1\) 返回原点。</p> <p>除了回返性，随机游走还有许多重要的性质，例如对于动点逗留时间讨论导出的反正弦定理，限于篇幅，这里不再赘述。</p> <h2 id="二维与三维随机游走">二维与三维随机游走</h2> <p>一维随机游走可以自然的推广到更高的维度：二维即在平面上以 \(\frac14\) 的概率向上、下、左、右移动一格；三维即在空间中以 \(\frac16\) 的概率向上、下、左、右、前、后移动一格。</p> <p>首先证明一条引理：</p> <p><strong>引理3</strong> \(u_{2n} = \sum_{k=1}^n f_{2k}u_{2n-2k}\)</p> <p>证明：由全概率公式和对于 \(u, f\) 的定义不难推得。</p> <p>有了这一引理，我们对左右两边求和：</p> <p>左式： \(\sum_{n=1}^\infty u_{2n} = \sum_{n=0}^\infty u_{2n} -1\).</p> <p>右式：\(\sum_{n=1}^\infty[\sum_{k=1}^n f_{2k}u_{2n-2k}] = \sum_{k=1}^\infty f_{2k}\sum_{n=0}^\infty u_{2n}\). (?)</p> <p>因此</p> \[\begin{array} \sum\sum_{n=0}^\infty u_{2n}-1 &amp;= \sum_{n=1}^\infty u_{2n} -1 =\sum_{k=1}^\infty f_{2k}\sum_{n=0}^\infty u_{2n} \\ \sum_{n=1}^\infty f_{2n} &amp;= 1 - \frac1{\sum_{n=0}^\infty u_{2n}} \end{array}\] <p>所以我们立刻得到：若级数 \(\sum u_{2n}\) 发散，那么 \(\sum f_{2n} = 1\)，即回到原点的概率为 \(1\). 反之，则回到原点的概率小于 \(1\).</p> <p>首先在二维随机游走中，我们求概率 \(u_{2n}\), 总路线有 \(4^{2n}\) 条，而回到原点则要求向上和向下的路线数相等，向左和向右的路线数相等，因此这样的路线为：</p> \[\sum_{k=0}^n\frac{(2n)!}{k!k!(n-k)!(n-k)!} = C_{2n}^n\sum_{k=0}^n (C_n^k)^2 = (C_{2n}^n)^2\] <p>那么同样利用斯特林公式：</p> \[u_{2n} = 4^{-2n}(C_{2n}^n)^2\approx \frac{1}{\pi n}\] <p>显然 \(\sum_{n=2}^\infty u_{2n} = \infty\)，这是一个经典的发散级数，故二维随机游走是回返的。</p> <p>而在三维随机游走中，我们有类似的：</p> \[u_{2n} = 6^{-2n}\sum_{0\le i + j \le n}\frac{(2n)!}{i!i!j!j!(n-i-j)!(n-i-j)!}\] <p>(以下省略一波暴算和估计)</p> <p>可以得到 \(u_{2n} 的数量级为 \frac{1}{n^{3/2}}\)，因此 \(\sum_{n=2}^\infty u_{2n} &lt; \infty\)，故三维随机游走是非回返的。经计算，回返的概率大约是 \(0.35\).</p> <p>综上所述，一维随机游动的一条极好性质——回返性，在二维空间仍然成立，然而在三维及三维以上空间就不满足了。</p> <blockquote> <p>随机游走的回返性最终与p级数的收敛性相关，这是一个非常有趣的结论。</p> </blockquote> <h2 id="参考资料">参考资料</h2> <p>柯尔莫哥洛夫. 《概率论导引》. 本文主要是对其第四章内容的总结与笔记。</p>]]></content><author><name>[&quot;詹奇&quot;]</name></author><category term="math"/><summary type="html"><![CDATA[A drunk man will find his way home, but a drunk bird may get lost forever.]]></summary></entry><entry><title type="html">算法趣谈(2)——快速平方根逆</title><link href="https://qi-zhan.github.io/blog/2023/algorithm2/" rel="alternate" type="text/html" title="算法趣谈(2)——快速平方根逆"/><published>2023-10-04T00:00:00+00:00</published><updated>2023-10-04T00:00:00+00:00</updated><id>https://qi-zhan.github.io/blog/2023/algorithm2</id><content type="html" xml:base="https://qi-zhan.github.io/blog/2023/algorithm2/"><![CDATA[<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">float</span> <span class="nf">inv_sqrt</span><span class="p">(</span><span class="kt">float</span> <span class="n">number</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">uint32_t</span> <span class="n">i</span><span class="p">;</span>
    <span class="kt">float</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y</span><span class="p">;</span>
    <span class="k">const</span> <span class="kt">float</span> <span class="n">threehalfs</span> <span class="o">=</span> <span class="mi">1</span><span class="p">.</span><span class="mi">5</span><span class="n">F</span><span class="p">;</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">number</span> <span class="o">*</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="n">F</span><span class="p">;</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">number</span><span class="p">;</span>
    <span class="n">i</span> <span class="o">=</span> <span class="o">*</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="o">*</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">y</span><span class="p">;</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mh">0x5f3759df</span> <span class="o">-</span> <span class="p">(</span><span class="n">i</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span><span class="p">);</span>
    <span class="n">y</span> <span class="o">=</span> <span class="o">*</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">i</span><span class="p">;</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="n">threehalfs</span> <span class="o">-</span> <span class="p">(</span><span class="n">x2</span> <span class="o">*</span> <span class="n">y</span> <span class="o">*</span> <span class="n">y</span><span class="p">));</span>
    <span class="c1">// y = y * (threehalfs - (x2 * y * y));</span>
    <span class="k">return</span> <span class="n">y</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>这是一段奇怪却又极富盛名的代码，通过一些使用令人费解的操作之后和奇怪的 <code class="language-plaintext highlighter-rouge">0x5f3759df</code>，返回了 <code class="language-plaintext highlighter-rouge">number</code> 的平方根的倒数，即 \(\frac1{\sqrt{number}}\). 这段代码就是 <a href="https://en.wikipedia.org/wiki/Quake_III_Arena">Quake III Arena</a> ，作者为 <a href="https://en.wikipedia.org/wiki/John_Carmack">John Carmack</a>.</p> <p>本文将介绍这段代码的原理。</p> <h3 id="ieee-754">IEEE 754</h3> <p>要想了解这个算法，我们得首先看看浮点数在计算机下的表示方法，即 <a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE 754</a> 标准。</p> <p>假设数字 \(x = 0.15625 = {0.00101}_2 = 1.01 \times 2^{-3}\)，那么在 IEEE 754 中，其表示为：</p> <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Float_example.svg/600px-Float_example.svg.png" alt="IEEE 754"/></p> <ul> <li>符号位：\(0\)，表示正数.</li> <li>指数位：\(E = 01111100\)，为 \(-3 + 127 = 124\) 得到，其目的是能够表示正负指数。</li> <li>尾数位：\(M = 01000000000000000000000\)，其真实值为 \(1 + \frac{M}{2^{23}} = 1 + 0.25 = 1.25 = 1.01_2\). 这里的 1 是因为 IEEE 754 中默认尾数位为 \(1.M\)，所以可以节省一位。</li> </ul> <p>我们可以得到</p> \[x = (1 + \frac{M}{2^{23}}) \times 2^{E - 127}\] <h3 id="对数的魔法">对数的魔法</h3> <p>接下来我们要做的就是看看我们能否尽可能的利用等价变形化简这个值并进行近似。 看到指数时一个自然的想法就是取对数，即</p> \[\begin{align*} x &amp;= (1 + \frac{M}{2^{23}}) \times 2^{E - 127}\\ \log_2 x &amp;= \log_2 (1 + \frac{M}{2^{23}}) + E - 127\\ &amp;\approx \frac{M}{2^{23}} + \mu + E - 127\\ &amp;= \frac{1}{2^{23}}(M + 2^{23} \times E) + \mu - 127 \end{align*}\] <p>注意到 \(M + 2^{23} \times E\) <em>恰好</em> 是 \(x\) 二进制下的表示。这一洞察为我们提供了一个近似的方法。</p> <h3 id="主算法">主算法</h3> <p>有了以上的铺垫，我们就可以开始看看这个算法了。</p> <h4 id="bit-hack">Bit Hack</h4> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">y</span> <span class="o">=</span> <span class="n">number</span><span class="p">;</span>
    <span class="n">i</span> <span class="o">=</span> <span class="o">*</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="o">*</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">y</span><span class="p">;</span>
</code></pre></div></div> <p>这是利用指针和地址将 \(y\) 作为无符号整型来得到该浮点数的二进制表示，不多赘述，后面的代码也是同理，只不过是将整型转为浮点型。</p> <h4 id="magic-number">Magic Number</h4> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">i</span> <span class="o">=</span> <span class="mh">0x5f3759df</span> <span class="o">-</span> <span class="p">(</span><span class="n">i</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span><span class="p">);</span> <span class="c1">// 这里的 i 即为 M + 2^23 x E</span>
</code></pre></div></div> <p>为了计算 \(z = \frac{1}{\sqrt{y}}\)，我们还是取对数，即 \(\log_2 z = -\frac12 \log_2 y\)，而根据上面的推导，我们有</p> \[\frac{1}{2^{23}}(M_z + 2^{23} \times E_z) + \mu - 127 = -\frac12(\frac{1}{2^{23}}(M_y + 2^{23} \times E_y) + \mu - 127)\] <p>不难得到</p> \[\begin{align*} M_z + 2^{23} \times E_z &amp;= \frac32 2^{23}(127-\mu) - \frac12(M_y + 2^{23} \times E_y)\\ &amp;= Magic - (i &gt;&gt; 1); \end{align*}\] <p>注意 \(\mu\) 是上文近似对数函数得到的，对于 \(\mu\) 值的选择也就决定了 magic number 的值。</p> <blockquote> <p>枚举还是计算？ 在以前听到这个算法的时候有个最大比较大的争议是 0x5f3759df 这个神奇的数字究竟是纯粹数学计算出来的还是枚举出来的。通过维基百科资料我的感觉是这是在一个范围内枚举出来的，因为这个值本身即使考虑牛顿迭代法也不是<strong>最优</strong>的。所以一个可能的结果是在通过计算得到一个范围，例如 0x5f37642f 这个在某些分布下表现较好的值，然后再基于这个值上下枚举出一个实际使用最合适的。</p> </blockquote> <h4 id="牛顿迭代法">牛顿迭代法</h4> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="n">threehalfs</span> <span class="o">-</span> <span class="p">(</span><span class="n">x2</span> <span class="o">*</span> <span class="n">y</span> <span class="o">*</span> <span class="n">y</span><span class="p">));</span>
</code></pre></div></div> <p>最后一步较为简单，是利用牛顿迭代法来进行近似，回顾一下牛顿迭代法的原理：</p> \[y_{n+1} = y_n - \frac{f(y_n)}{f'(y_n)}\] <p>而对应于 \(f(y) = \frac{1}{y^2} - x\)，我们有</p> \[\begin{align*} f'(y) &amp;= -\frac2{y^3}\\ y_{n+1} &amp;= y_n - \frac{\frac1{y_n^2} - x}{-\frac2{y_n^3}}\\ &amp;= y_n + \frac{y_n - xy_n^3}{2}\\ &amp;= y_n(\frac32 - \frac{x}{2}y_n^2) \end{align*}\] <p>也就对应了上面的代码。</p> <h3 id="意义与应用">意义与应用</h3> <p>快速平方根逆算法的应用或者说是来源主要是图形学中的单位向量计算。如 \(v = (v_1, v_2, v_3)\), \(\Vert v \Vert = \sqrt{v_1^2 + v_2^2 + v_3^2}\), 则单位向量为 \(\frac{v}{\Vert v\Vert}\), 也就要用到平方根逆算法。</p> <p>但随着硬件的发展，这个算法已经没那么重要了，例如在 <a href="https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions">SSE</a> 中有一个指令 <code class="language-plaintext highlighter-rouge">rsqrtss</code> 就是专门用来计算平方根逆的，速度和准度都比这个算法要好。当然这些并不影响这个算法的魅力。</p> <blockquote> <p>本文主要参考<a href="https://www.youtube.com/watch?v=p8u_k2LIZyo&amp;t=3s">该视频</a>和<a href="https://en.wikipedia.org/wiki/Fast_inverse_square_root">维基百科</a>.</p> </blockquote>]]></content><author><name>[&quot;詹奇&quot;]</name></author><category term="algorithm"/><summary type="html"><![CDATA[float inv_sqrt(float number) { uint32_t i; float x2, y; const float threehalfs=1.5F; x2=number * 0.5F; y=number; i=*(uint32_t *) &amp;y; i=0x5f3759df - (i &gt;&gt; 1); y=*(float *) &amp;i; y=y * (threehalfs - (x2 * y * y)); // y=y * (threehalfs - (x2 * y * y)); return y; }]]></summary></entry><entry><title type="html">算法趣谈(1)——秘书问题与37%法则</title><link href="https://qi-zhan.github.io/blog/2023/algorithm0/" rel="alternate" type="text/html" title="算法趣谈(1)——秘书问题与37%法则"/><published>2023-05-18T00:00:00+00:00</published><updated>2023-05-18T00:00:00+00:00</updated><id>https://qi-zhan.github.io/blog/2023/algorithm0</id><content type="html" xml:base="https://qi-zhan.github.io/blog/2023/algorithm0/"><![CDATA[<p>假如你是一家公司的老板，你要找一个秘书。假设有 \(N\) 个候选者应聘，每个候选者都有能力值。而你能做的是应聘完一个候选者后，获得他的能力值，然后立刻选择要不要选其作为你的秘书。如果你选择了该候选者，那么应聘结束，剩下的候选者也就不必再看了；如果你不选该候选者，那么你就不能回头再来选择这个人了。那么，你该采取什么样的策略，才能最大化你选到最优候选者(能力值最大)的概率呢？</p> <p>这是一个经典的在线算法的例子，也被称为候选人问题，结婚问题等等。计院 <em>著名课程</em> 高级数据结构与算法分析(俗称ADS)中也有对此的讨论。一个经典且正确的思路是我们必须先看一部分人，残忍的拒绝他们，看完之后我们对这批人的水平有了大概的了解，然后选择下一个比他们都要优秀的人作为最终的秘书。那么我们该拒绝多少人才比较合适呢？</p> <p>首先最优候选人处在第 \(i\) 个的概率都是 \(\frac1N\) ，假设我们选择放弃 \(m\) 个人，那么想要选到最优的候选人就要满足：在面试他之前我们不能选了别人。还记得我们的策略是说选择第一个比前 \(m\) 个人都要优秀的候选者吗，也就是说前 \(i-1\) 个人中最优秀的那个得在前面 \(m\) 个人里面，不然我们就会选择这个人而不是第 \(i\) 号位的最优人选。而前 \(i-1\) 个人最优秀的那个在前 \(m\) 人中的概率显然是 \(\frac{m}{i-1}\)，所以我们得到最终概率就是对其进行求和，即为：</p> \[P=\frac mN\sum_{i=m+1}^N\frac1{i-1}\] <p>注意这里的 \(i\) 是从 \(m+1\) 开始的，因为前 \(m\) 个人我们放弃了所以如果最有候选人在前 \(m\) 个人里面，我们选中的概率即为0。而我们熟悉的近似式 \(\sum\frac1i\approx \ln i\) 告诉我们：</p> <p>\(P\approx\frac mN(\ln N-\ln m)=-\frac mN\ln\frac mN\) 对其进行求导可以得到 \(\frac mN=\frac1e\) 时，概率最大，为 \(\frac1e\).</p> <p>如果有了解过这个问题的同学到这一步想必都是熟悉的，我们得到了 \(\frac1e\) 的优雅答案，而 \(\frac1e\) 约等于 37%，也就有了我们平常所说的 37%法则。</p> <p>但是其实问题还没完，我们只证明了<strong>如果我们的策略是选择一部分人并放弃掉，然后选择下一个比这些人都优秀的人的话，那么当人数趋于正无穷时，放弃的人比例最优值是 \(\frac1e\) ，但我们想要证明的是</strong>任意一个策略，最终能选到最优秀的人的概率都不会比我们上面的方法更高，即我们的策略是<strong>最优的</strong> 。 举个例子，我们可以选择第二个比这些人都优秀的人，可以选择下一个比半数放弃的人都要优秀的人，甚至可以直接选择第一个人(当然这肯定是不靠谱的)。</p> <p>而这个问题同样早就被解决了，我们介绍Beckmann在1990年Dynamic Programming and the Secretary Problem中提出的基于动态规划的分析。</p> <p>首先我们介绍两个非常重要的函数/数列，它们能帮助我们解决问题：</p> <p>\(v_m\) 是已经看过 \(m\) 个候选者而且我们没有选第 \(m\) 个候选者的情况下，我们能选中最优候选者的概率。</p> <p>\(u_m\) 是已经看过 \(m\) 个候选者而且第 \(m\) 个候选者是目前最优的情况下，我们能选中最优候选者的概率。</p> <p><strong>假设我们的策略是最优的</strong>，那么我们可以得到以下两个式子：</p> \[v_m=\frac m{m+1}v_{m+1}+\frac1{m+1}u_{m+1}\] <p>若第 \(m\) 个候选者没有被选择，第 \(m+1\) 候选者要么是目前为止最好的(概率为 \(\frac1{m+1}\))，要么不是(概率为 \(\frac{m}{m+1}\))。如果不是，那么选中最好的概率就变成 \(v_{m+1}\)，因为最优解一定不会选择第 \(m+1\) 个候选者；而如果是的话，概率就自然变成我们所定义的 \(u_m\).</p> \[u_m=\max(\frac mN,v_m)\] <p>如果已经看过 \(m\) 个候选者而且第 \(m\) 个候选者是目前最优的情况下(\(u_m\) 的定义)，那么我们的选择就变成了我们要选择该候选者或者继续。如果选择这个候选者，那么我们能选择最优候选者的概率就是 \(\frac mN\)，因为我们总共看过 \(m\) 个人且我们选择的其中最好的；而如果继续下去，概率就变成了 \(v_m\)，正如我们定义的那样。</p> <p>有趣的是，这两个式子已经 <em>完全描述</em> 了最优解的结构，我们可以将所有值都解出来。根据定义 \(v_N=0,u_N=1\)，那么我们可以推出</p> \[v_{N-1}=\frac{N-1}Nv_N+\frac1Nu_N=\frac1N\\ u_{N-1}=\max(\frac{N-1}N,v_{N-1})=\frac{N-1}N\] <p>继续写下去我们可以发现规律，在 \(\frac mN\ge v_m\) 即 \(u_m=\frac mN\) 的时候利用数学归纳法不难证明：</p> \[v_m=\frac mN(\frac1m+\frac1{m+1}+\dots+\frac1{N-1})\\ u_m=\frac mN\max(1,\frac1m+\frac1{m+1}+\dots+\frac1{N-1})\] <p>而随着 \(m\) 的减小，\(u_m\) 中 \(\frac1m+\dots+\frac1{N-1}\) 也会越来越大最终超过1，我们令最后一个不超过1的值为 \(m^*\)，即</p> \[\sum_{i=m^*}^{N-1}\frac1i\le1&lt;\sum_{i=m^*-1}^{N-1}\frac1i\] <p>从这里开始，我们上文归纳出的式子不再适用，但事情实际上更简单了，因为 \(u_m\) 从现在开始就等于 \(v_m\)，而更好的是由于这一点 \(v_m=v_{m+1}\) 从而 \(u_0=v_0=v_{m^*-1}\). 它的意思是当 \(m\) 小到一定程度上的时候，\(u_m\) 就是 \(v_m\)，由它们的定义我们知道这就是说如果看的候选者太少了，那么即使你是目前最好的候选者，也不会选择你。极端情况下我们很容易理解这件事，如果我们只看了一个人，那么这个人当然是目前最好的候选者，</p> <p>相信读者已经发现了， \(m^*\) 其实就对应着我们所说的放弃的那一部分人。注意到 \(v_0\) 的意思是在我们什么都还没看的时候，能选中最优解的概率，那就是我们所求的答案! \(v_0=v_{m^*-1}=\frac{m^*-1}N(\sum_{m^*-1}^{N-1}{\frac1i})\) 而这和我们上文所说的放弃一部分人然后选则第一个的策略的概率，即式(1)是一致的，这就完成了证明。</p> <p>总结一下，在秘书问题中，如果想要最大化选到最优者的概率，我们证明了：</p> <ul> <li>对于每一个 \(N\) ，放弃一部分人并且选择第一个比这些放弃的人都好的人的这一族算法，都是最优的策略。该放弃的人的比例对应上文的 \(m^*\).</li> <li>当 \(N\to\infty\) 时，最优的放弃比例是 \(\frac1e\)，我们选中最优的人的概率亦为 \(\frac1e\).</li> </ul>]]></content><author><name>[&quot;詹奇&quot;]</name></author><category term="algorithm"/><summary type="html"><![CDATA[假如你是一家公司的老板，你要找一个秘书。假设有 \(N\) 个候选者应聘，每个候选者都有能力值。而你能做的是应聘完一个候选者后，获得他的能力值，然后立刻选择要不要选其作为你的秘书。如果你选择了该候选者，那么应聘结束，剩下的候选者也就不必再看了；如果你不选该候选者，那么你就不能回头再来选择这个人了。那么，你该采取什么样的策略，才能最大化你选到最优候选者(能力值最大)的概率呢？]]></summary></entry><entry><title type="html">算法趣谈(0)——古老的石子游戏</title><link href="https://qi-zhan.github.io/blog/2022/algorithm1/" rel="alternate" type="text/html" title="算法趣谈(0)——古老的石子游戏"/><published>2022-08-09T00:00:00+00:00</published><updated>2022-08-09T00:00:00+00:00</updated><id>https://qi-zhan.github.io/blog/2022/algorithm1</id><content type="html" xml:base="https://qi-zhan.github.io/blog/2022/algorithm1/"><![CDATA[<p>相信很多人在小学数学题或其他地方都见过这样一个游戏：从1开始，每人依次报1-3个数，先报到20的人胜利。而本文正是介绍组合博弈中的这一类游戏——捡石子，并介绍数学家发展出的一般理论与证明。</p> <h3 id="阅读本文的可能的收获">阅读本文的可能的收获</h3> <ul> <li> <p>相较于可以直接搜索到的各种有关石子博弈的文章，本文更系统的介绍这些经典的石子游戏并给出结论，读者在掌握方法后就可以和别人<strong>愉快</strong>的玩耍了(doge)。</p> </li> <li> <p>本文会给出对于这些博弈的未经审视的证明供大家参考。虽然本文的核心思路和概念来自各路证明(我当然想不出来这么巧妙的方法)，但语言和证明细节都由我自己完成，很有可能是存在缺陷的，也希望读者在阅读过程中也能帮忙检查这些证明。</p> </li> </ul> <p>我们先借最简单的巴什博弈来介绍先手、后手必胜和奇异局势等基本概念，而这些概念则会贯穿所有博弈。</p> <h3 id="巴什博弈-bash-game">巴什博弈 Bash Game</h3> <p><strong>游戏描述：场上有1堆石子，数目为n个，双方依次拿1~ m个石子(\(m\) 为定义好的正整数)，拿到最后一个石子的玩家获胜。</strong></p> <p>相信大家在许多场合已经见过这个游戏，并且大概已经知道了答案：</p> <ul> <li>若n是(1+m)的倍数，先手必胜。</li> <li>反之，后手必胜。</li> </ul> <p>等等，我们需要先简单且<strong>不严谨</strong>的定义一下这些概念：</p> <h4 id="定义1必胜">定义1：必胜</h4> <p>若玩家在当前局势下，无论对手进行任何符合规则的操作，该玩家都能有相应的<strong>策略</strong>赢得最终的胜利，则称玩家在该局势下是<strong>必胜</strong>的。若首先行动的玩家是必胜的，则称该游戏是<strong>先手必胜</strong>的，若后行动的玩家是必胜的，则称<strong>后手必胜</strong>。</p> <blockquote> <p>事实上，经典的石子游戏属于两人组合策略博弈，必然存在先手必胜或后手必胜。 严谨的关于策略、必胜等的定义其实也并不困难，但本文重点不在于此，感兴趣的读者可以在任何一本正经的博弈论教材中找到相关定义。</p> </blockquote> <p>当我们知道这个答案后不难猜出答案的来源，一个玩家总是有办法将一轮双方取石子总数控制在1+m，那如果石子的数目不是模为0，先手方只需要拿石子，使得剩下的石子是 1+m 的倍数，然后每次都将剩下的石子数控制在 k(1+m)，直到石子被拿完。</p> <blockquote> <p>较为严格的证明会在下文给出。</p> </blockquote> <p>上述过程显然不难理解，而值得思考和推广的核心在于石子是1+m的倍数这种局面，我们有以下发现：</p> <ol> <li>0(1+m)=0，即如果玩家进行操作，将局势转换这该情况，该玩家获胜。</li> <li>如果当前局面是(1+m)倍数，那么玩家无论选择在规则下拿几个石子(1~m)，剩下的石子总不会是其倍数。</li> <li>如果当前局面不是(1+m)倍数，那么该玩家总可以拿部分石子，使得剩下的石子总数是(1+m)的倍数。</li> </ol> <p>而将这种局面进行抽象，也就得到了本文的核心概念：</p> <h4 id="定义2奇异局势">定义2：奇异局势</h4> <p>假设有 \(l\) 堆石子个数分别为 \(n_1,\dots,n_l\) (简称 \((n_i)\))，我们记所有局势的集合为\(U=\{(a_1,\dots,a_l)\},a_i\le n_i,a_i\in \mathbb{N}\)，即所有可能发生的石子数组成的集合。 若集合 \(S\subset U\)满足如下性质：</p> <ol> <li>\(0\in S\)，这里的0实际上指的是 \((0,\dots,0)\)</li> <li>若当前局势 \((s_i)\in S\) 且 \((s_i)\ne0\)，那么进行任一符合规则的操作，新的局势不是奇异局势， \((s_i')\in U\setminus S\)</li> <li>若当前局势不是奇异局势，即 \((s_i)\in U\setminus S\)，那么存在一符合规则的操作，新的局势 \((s'_i)\in S\)</li> </ol> <p>我们称集合 \(S\) 是代表<strong>奇异局势</strong>的集合，集合中的元素是<strong>奇异</strong>的。</p> <p>奇异局势将巴什博弈的特殊的局面抽象出来，我们再将其结论也抽象出来：</p> <h3 id="定理1">定理1</h3> <p>若该博弈存在上述定义的奇异局势，那么：</p> <ol> <li> <p>若初始局势 \((n_i)\) 不是奇异局势，则先手必胜。</p> </li> <li> <p>若初始局势 \((n_i)\) 是奇异局势，则后手必胜。</p> </li> </ol> <p>证明：首先我们有如下观察：</p> <ul> <li>因为每位玩家必须取石子，所以石子的数目一定严格小于上一步的数目，游戏一定在有限步内终止。</li> <li>由奇异局势定义，(1) 和 (2) 是等价的，所以我们只证明(2).</li> </ul> <p>我们对场上石子数目采用数学归纳法证明。若初始局势 \((n_i)=0\)，是奇异局势，则先手方无子可拿，后手胜。 若 \((n_i)&gt;0\)，将双方一轮博弈后的局势看作一个新游戏的初始局势，此时的石子数严格小于原博弈石子数。由归纳假设我们知道，若这个局势 \((n''_i)\) 是奇异局势，则后手必胜。那么后手方如何确保这个局势是奇异局势呢？这就用到了奇异局势的定义和初始条件。由定义2(2)我们知道，先手者进行任何操作进入的局势 \((n'_i)\) 必然不属于奇异局势。而由于0是奇异局势，场面上一定还有石子，由定义2(3)后手者一定可以在取石子后使得新的局势 \((n_i')\) 是奇异局势，这就是我们希望的。</p> <blockquote> <p>这个定理直觉是是显然的，利用数学归纳法我认为能比较清楚的证明它。</p> </blockquote> <p>奇异局势可以看作某种意义上的<strong>不变量</strong>。上述定义和定理给了我们一套解决这类问题的<strong>范式</strong>：找到并证明该游戏的奇异局势，本文介绍的石子游戏证明都会通过这种方法来描述。</p> <p>本节最后我们用奇异局势的语言证明巴什博弈的结论，感受一下抽象的力量(bushi)：</p> <h3 id="定理2巴什博弈">定理2：巴什博弈</h3> <p>\(S = \{s\mid s\equiv 0\mod (1+m)\}\)只需证明：</p> <ol> <li> \[0\equiv 0\implies 0\in S\] </li> <li>由于是 \(s\) 是奇异局势且 \(s\ne 0\)，我们令 \(s=k(1+m),k\ge1\)，若拿 \(1\le t\le m\) 个石子，则 \(s'=(k-1)(1+m)+(1+m-t)\) ， \(s'\equiv (1+m-t),1\le(1+m-t)\le m\implies s'\notin S\)</li> <li>由于 \(s\) 不是奇异局势，由带余除法我们知道 \(s=k(1+m)+r,1\le r\le m\)，所以只需取 \(r\) 个石子即可。(我们也证明了取法是唯一的)</li> </ol> <p>可能有读者还是觉得本节的内容太平凡了，不过是在奇异局势的语言下叙述了这件事，其证明本质大概是我们小学就会的带余除法，下一节我们会介绍一个有难度的游戏：</p> <h3 id="尼姆博弈-nim-game">尼姆博弈 (Nim Game)</h3> <p><strong>游戏描述：</strong> 场上有 \(l\) 堆石子，双方依次选择某一堆石子，取至少一个石子，拿到最后一个石子的玩家获胜。</p> <p>这个游戏最经典的版本是[3, 4, 5]的情形，先手必胜。感兴趣的读者可以自己先玩玩看。</p> <p>由上面的讨论，我们知道，我们的最终目的是找到一个局势的集合，使得它满足奇异局势的要求，即找到函数 \(f(n_1,\dots,n_l)\to\{0,1\}\)，来判定一个局势是否是先手必胜(1)还是后手必胜(0)。虽然任意多堆和拿任意多石子让问题难以入手，但我们还是可以有以下观察：</p> <ul> <li>\(f\) 是对称的，多元函数交换变量顺序结果是不变的。</li> <li>只剩一堆石子时，先手必胜，因为玩家可以直接拿完所有石子。</li> <li>只剩两堆石子时，也不难想到答案。如果两堆石子数目相同，那后手方总可以在另一堆石子上重复先手方的操作，从而使得两堆石子同时为0，此时先手放无子可拿。</li> <li>还剩三堆石子时就麻烦了，如果存在两堆石子数目相同，这时我们直接把另一堆拿完，就回到了 \(l=2\)的情形，但如果没有的话我们似乎没有什么办法了…</li> </ul> <p>两堆石子的情况给了我们很大的启发，相同则函数输出为0，后手必胜；不同则函数输出为1，先手必胜。那么什么运算满足这个性质呢？</p> <p><strong>异或！</strong> 相同为0，不同为1，异或运算可以完成这件事。而两个数的异或运算实质上是在二进制表示上进行的逐位异或。而令人惊奇的是，<strong>尼姆博弈中奇异局势等价判断一列数异或是否为0</strong>：</p> <h4 id="例1345">例1：[3,4,5]</h4> <p>回到本节开头，一个经典的先手必胜场景：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            3 = 011   -2   1 = 001          
            4 = 100        4 = 100          
            5 = 101        5 = 101   ...    
         XOR ______     XOR ______          
              = 010          = 000          
</code></pre></div></div> <blockquote> <p><strong>这个结论由数学家Charles L. Bouton在1901-1902年 Annals of Mathematics上给出</strong></p> </blockquote> <p>而接下来我们需要证明这一点：</p> <h3 id="定理3尼姆博弈">定理3：尼姆博弈</h3> <p>由上一节的定理1我们只要证明 \(S=\{(s_i)\mid \bigoplus_{i=1}^{l}(s_i)=0\}\)是奇异局势，即 ：</p> <ol> <li> <p>\(0\in S\)，这是显然的</p> </li> <li> <p>若 \((s_i)\in S\)，我们要证明任取 \(0\le s_k'&lt; s_k ， (s_1,\dots,s_{k-1},s'_,s_{k+1},\dots,s_l)\notin S\) ，这并不困难。我们假设存在一种取法使得异或为0，即\((\bigoplus_{i\ne k}s_i)\oplus s_k'=0\)，那么我们添加上两个异或，可以得到</p> </li> </ol> \[s_k\oplus(\bigoplus_{i\ne k}s_i)\oplus s_k' \oplus s_k= s_k\oplus s_k\\ 0 \oplus s_k' \oplus s_k = 0\\ s_k' = s_k\] <p>这与 \(s_k'\le s_k\) 矛盾，故假设不成立，不存在这种取法。</p> <ol> <li>若 \((s_i)\notin S\)，我们要证明必存在 \(0\le s_k'&lt; s_k\) 使得 \((s_1,\dots,s_{k-1},s'_k,s_{k+1},\dots,s_l)\in S\). 因为 \(\bigoplus_{i=1}^{l}(s_i)\ne0\)，则我们可以找到二进制最左边的1(例子中<code class="language-plaintext highlighter-rouge">010</code>的1)，那么此时石子堆中必然有 \(s_k\) 其该位值为1（如果全0异或之后也还是0），我们就令 \(s_k' = s_k \oplus \bigoplus_{i=1}^{l}(s_i)\)，由 \(s_k\) 的选取我们知道最前面的1被异或成0了，所以 \(s'_k\lt s_k\)，这是一个合法的操作。另一方面， \((\bigoplus_{i\ne k}s_i)\oplus s_k' = (\bigoplus_{i\ne k}s_i)\oplus s_k \oplus \bigoplus_{i=1}^{l}(s_i) = 0\) 这就是所要证明的。</li> </ol> <p>大家可能已经发现了，虽然我们想不出来答案，但如果告诉我们结论，证明还是相对容易的。</p> <p>最后，我们会介绍一个证明本身也不太容易的博弈——威佐夫博弈。</p> <h3 id="威佐夫博弈-wythoff-game">威佐夫博弈 Wythoff Game</h3> <p><strong>游戏描述：</strong> 有两堆石子，双方依次进行选择：从两堆里面拿相同多的石子，或者从一堆里面拿任意多的石子。拿到最后一个石子的玩家胜利。</p> <p>这个问题没啥好观察的，因为我也观察不出来，我们直接给出结论：</p> \[\alpha=(1+\sqrt{5}) / 2, \beta=(3+\sqrt{5}) / 2 \\ S=\{(\lfloor n \alpha\rfloor,\lfloor n \beta\rfloor)\mid n \in \mathbb{Z}\}\cup\{(\lfloor n \beta\rfloor,\lfloor n \alpha\rfloor)\mid n \in \mathbb{Z}\},\] <p>即奇异局势是由这些奇怪的无理数的倍数取下整得到的。为了证明这确实是奇异局势，我们需要先证明一个引理：</p> <h3 id="引理-beatty定理">引理: Beatty定理</h3> <p>若正<strong>无理数</strong>满足 \(\frac1p+\frac1q=1\)，那么</p> \[P=\left\{\lfloor n p\rfloor\mid n \in \mathbb{Z}^{+}\right\}, Q=\left\{\lfloor m y\rfloor\mid m \in \mathbb{Z}^{+}\right\}\] <p>是一个正整数集的划分。</p> <p>我们要证明两点：</p> <ol> <li> <p>\(\forall z\in \mathbb Z^+ \implies z\in P \lor z\in Q\) 反证法。若 \(z\notin P \land z\notin Q\)，即 \(np&lt;z&lt;z+1&lt;(n+1)p,mq&lt;z&lt;z+1&lt;(m+1)q\\ \frac{n+m}z &lt;\frac1p+\frac1q=1&lt; \frac{n+1}{z+1}+\frac{m+1}{z+1}\\ n+m&lt;z&lt;n+m+1\) 这与 \(n,m,z\) 都是整数矛盾。</p> </li> <li> <p>\(\forall z\in \mathbb Z^+ \implies \neg( z\in P \land z\in Q)\) 反证法。若 \(z\in P \land z\in Q\)，即 \(z&lt;np&lt;z+1,z&lt;mq&lt;z+1\\ \frac n{z+1}+\frac m{z+1} &lt;\frac1p+\frac1q=1&lt; \frac nz+\frac mz \\ z&lt;n+m&lt;z+1\) 这与 \(n,m,z\) 都是整数矛盾。</p> </li> </ol> <p>我们发现\(\frac1\alpha+\frac1\beta=1\)，所以可以使用该引理得到一组划分，另外还注意到 \(\beta=\alpha+1\)，所以我们只需证明：</p> <blockquote> <p><strong>这个结论由数学家Willem A. Wythoff在1907年给出</strong></p> </blockquote> <h3 id="定理4威佐夫博弈">定理4：威佐夫博弈</h3> <p>\(S=\{(\lfloor n\alpha\rfloor,\lfloor n\alpha\rfloor+n),n\in\mathbb Z\}\) 是奇异局势，具体来说，我们要证明：</p> <ol> <li> <p>\((0,0)\in S\)，\(n=0\) 即可。</p> </li> <li> <p>\(s=(\lfloor n\alpha\rfloor,\lfloor n\alpha\rfloor+n)\in S\)，如果选择某堆拿石子的话只能拿多的那堆，由引理的分划性 \(s'\notin S\)，而如果两堆同时拿 \(k\) 个石子且还是奇异局势的话， \(s'=(\lfloor n\alpha\rfloor-k,\lfloor n\alpha\rfloor+n-k)\in S\\ \implies \begin{matrix}\lfloor n\alpha\rfloor-k=\lfloor n_1\alpha\rfloor \\ \lfloor n\alpha\rfloor+n-k= \lfloor n_1\alpha\rfloor+n_1 \end{matrix}\implies n=n_1\) 矛盾，故 \(s'\notin S\)</p> </li> <li> <p>\(s=(s_1,s_2)\notin S，s_1\le s_2\)（对称性假设），由引理中的分划性有以下情况：</p> <ul> <li>\(s_1=\lfloor n\alpha\rfloor,s_2&gt;=s_1,\)，若 \(s_2-s_1&gt;=n+1\) ，把 \(s_2\) 取到 \(s_1+n\)即可。若 \(s_2-s_1\lt n\)，那么我们知道将两堆各取某些石子，结果必然是 \((\lfloor (s_2-s_1)\alpha\rfloor,\lfloor (s_2-s_1)\alpha\rfloor+(s_2-s_1))\)，为奇异局势。</li> <li>\(s_1=\lfloor n\alpha\rfloor+n,s_2\ge s_1\)，将 \(s_2\) 取到 \(\lfloor n\alpha\rfloor\) 即可。</li> </ul> </li> </ol> <blockquote> <p><a href="https://zhuanlan.zhihu.com/p/454084562">Wythoff 博弈及其扩展 - 知乎 (zhihu.com)</a> 有些对于 \(\alpha,\beta\) 的有趣探讨和扩展。</p> </blockquote> <p>综上所述，我们就在奇异局势的框架下完成了三个最经典的石子游戏的证明。</p>]]></content><author><name>[&quot;詹奇&quot;]</name></author><category term="algorithm"/><summary type="html"><![CDATA[相信很多人在小学数学题或其他地方都见过这样一个游戏：从1开始，每人依次报1-3个数，先报到20的人胜利。而本文正是介绍组合博弈中的这一类游戏——捡石子，并介绍数学家发展出的一般理论与证明。]]></summary></entry></feed>